Availability: Public
Crumbs: %ROOT%
Title:Virtual Reality Best Practices
Description: Information about developing for VR.
Type: Overview
SkillLevel: Beginner
Version:4.17
Parent: Platforms/VR/DevelopVR
Order:4
Tags:VR


[TOC(start:2)]

Developing content for Virtual Reality (VR) does require a few workflow adjustments to ensure that the user has the best 
VR experience possible. The purpose of this guide is to help point out some of the main things that you should be aware of when 
developing content for your VR projects. 

##	VR Project Settings
When creating a new project for VR, whether the project is Blueprint based or C++ based, it is best to create a project that uses the **Mobile / Tablet** option 
with **Scalable 3D or 2D** graphics and **No Starter Content** to ensure that your VR project will be running at frame right from the start. 

[REGION:lightbox]
[![](VR_Project_Settings.png)(w:400)](VR_Project_Settings.png)
[/REGION]

[REGION:caption]
Click for full image.
[/REGION]

## VR .INI Settings

The following .INI settings were taken from the UE4 powered, VR demo, Showdown. 
These . INIsettings, if used, should be added to your project's **Config\DefaultEngine.INI** file, under **SystemSettings**. 

	[SystemSettings]
	vr.PixelDensity=1
	r.SeparateTranslucency=0
	r.HZBOcclusion=0
	r.MotionBlurQuality=0
	r.PostProcessAAQuality=3
	r.BloomQuality=1
	r.EyeAdaptationQuality=0
	r.AmbientOcclusionLevels=0
	r.SSR.Quality=1
	r.DepthOfFieldQuality=0
	r.SceneColorFormat=2
	r.TranslucencyVolumeBlur=0
	r.TranslucencyLightingVolumeDim=4
	r.MaxAnisotropy=8
	r.LensFlareQuality=0
	r.SceneColorFringeQuality=0
	r.FastBlurThreshold=0
	r.SSR.MaxRoughness=0.1
	r.rhicmdbypass=0
	sg.EffectsQuality=2
	sg.PostProcessQuality=0

## VR World Scale

Ensuring the correct scale of your world is one of the most important ways to help deliver the best user experience possible 
on VR platforms. Having the wrong scale can lead to all kinds of sensory issues for users, and could even result in Simulation 
Sickness. Objects are most easily viewed in VR when they are in a range of **0.75 to 3.5 Meters** from the player's camera. 
Inside of UE4, **1 Unreal Unit (UU) is equal to 1 Centimeter (CM)**. This means that objects inside of Unreal are best viewed 
when they are **75 UU to 350 UU** away from the player's camera (when using VR). 
 
| Distance  | Distance in Unreal Units(UU) |
| --- | --- |
| 1 Centimeter | 1 Unreal Unit|
| 1 Meter|100 Unreal Units|
| 1 Kilometer | 100,000 Unreal Units|

You can adjust the scale of your world using the **World to Meters** variable that is located under **World Settings**.
Increasing or decreasing this number will make the user feel bigger or smaller in relation to the world around them. 
Assuming your content was built with 1 Unreal Unit = 1 CM, setting **World To Meters** to **10** will make the world appear to be very big, while setting 
**World To Meters** to **1000** will make the world appear to be very small.

![](T_VR_World_To_Meters_00.png)

## VR and Simulation Sickness

Simulation Sickness is a form of motion sickness that occurs when using HMD devices in a VR world. Simulation Sickness can 
greatly affect a user's VR experience and in some cases, ruin the VR experience all together. To help reduce the likelihood 
of your user having a bad VR experience, follow the best practices listed below **closely**. If you do not do this, your users 
could end up having a very unpleasant VR experience.    

* You must maintain framerate, and ideally, a little bit of a buffer to make sure you're always over the HMD's native framerate.
Low framerates are another trigger for Simulation Sickness, so make sure to optimize your project as much as possible. 
The following table shows the various HMD's UE4 supports, and the target frame rates your VR project needs to run at on those devices.

	| HMD Device  | Target Frame Rate |
	| --- | --- |
	| DK1 | 60 FPS|
	| DK2 | 75 FPS|
	| Rift Retail | 90 FPS|
	| Vive | 90 FPS|
	| Gear VR | 60 FPS|
	| PSVR | Variable up to 120 FPS|

* Developers make the worst test subjects, because they are often used to using VR devices. Check your game as much as you can, with as many different people as you can, to make sure that you are not causing Simulation Sickness.
* Avoid cinematic cameras, or anything that takes control of camera movements away from the player, as this tends to be the biggest culprit of your user having a bad VR experience.
* Do Not override the Field of View (FOV) manually, and Do Not expose this to the end user for editing purposes. The value needs to match the physical geometry of the headset and lenses, which should be automatically set through the device's SDK and internal configuration. If there is a mismatch, the world will appear to warp when you turn your head, leading to discomfort or nausea. 
* Do Not have "Walking Bob" for a camera effect (like in most first person games). Causing the camera to move up and down to mimic the movement of the human body will give player Simulation Sickness, ruin their VR experience. 
* Do Not "Shake" the camera when trying to relay an event to the player. If a grenade goes off next to a player, a camera shake may make sense in non-VR games, but in VR games, it can trigger Simulation Sickness very quickly.
* When you are designing worlds and levels for your VR game, make sure to use dimmer lights and colors than you normally would. Strong and vibrant lighting in VR games can cause Simulation Sickness to occur more quickly. Avoid this by using cooler shades and dimmer lights than you normally would.
* Avoid stairs and use lifts instead. When the player is moving quickly, especially up and down stairs, it can be very disorienting.
* Players should all start out going full speed and not gradually accelerate to full speed. Also, movement speed should always be at a constant rate of acceleration. 
* Do Not use Depth of Field or Motion Blur post processes, because they can greatly affect what the user is seeing and, more importantly, they can give the user Simulation Sickness. 

Please note that this list is not an exhaustive compilation of root causes for Simulation Sickness; however, it should give you a good idea of what might be causing your players to fall ill while playing your VR game.

## VR Camera Setup
How your VR camera is setup in UE4 depends entirely on whether your VR experience is seated or standing.
In a seated experience, you will need to artificially raise the camera origin for the character to be standing. 
However, for a standing experience, you should make sure that the camera origin is at 0 (on the ground). 
You can achieve either effects by attaching a camera component to a scene component at the base of the character (ground level), or by setting the Eye Height to half of the 
(negative) Cylinder Height of the collision capsule on the character.

[OBJECT:ComparisonSlider]
	[PARAM:before]
	![Standing VR Camera](VR_Standing_Experiance.png)(w:500)
	[/PARAM]
	[PARAM:after]
	![Seated VR Camera](VR_Seated_Experiance.png)(w:500)
	[/PARAM]
[/OBJECT]

## VR Character Settings

The setup for a character using a VR headset is slightly different than for a standard character. Things like character 
Height, Width, Speed, and Camera Location all need to be slightly modified to accommodate a VR character.   

[REGION:tip]
 When building objects for a VR world, it is important that you make the scale of your digital object the same as their real 
 world counterpart. Making things bigger or smaller than they are in the real world, can ruin the immersion that you are trying 
 to achieve. 
[/REGION]
 
 **Character Height & Width**

Character Height & Width should mimic real life measurements as much as possible. Using sizes that are too big or two small, 
can ruin the immersion that you are trying to achieve.  

|Property| UE4 Default | Recommended VR |
|---| --- | --- |
|Height:| 192 cm|176 cm|
|Width:| 84 cm|68 cm|

**Movement Speed**

VR movement speed is a difficult property to recommend a setting for, because the movement speed that you choose will mainly be 
determined by the type of experience that you are trying to achieve. For example, in the Elemental VR demo, the movement speed 
was cut to about 1/4 normal speed.  

|Property| UE4 Default | Recommended VR |
|---| --- | --- |
Movement Speed:|60 m/s|24 m/s|

**Camera Location**

The VR camera needs to be positioned slightly lower than the base eye height to compensate for being at the character's eye level.  

|Property| UE4 Default | Recommended VR |
|---| --- | --- |
Base Eye Height:|180 cm|160 cm|


## VR Content Considerations

When creating VR content, remember that users can look at that content from multiple angles. Here are few things that you might 
have done in the past, but need to avoid in VR:

 * **Scale** - The best thing to do about the scale of the objects in your VR world, is to mimic reality as closely as you can. Making objects bigger or smaller than their real world counterparts could lead to confusion or Simulation Sickness.

 * **Missing Polygon Faces** - In standard games, it is often acceptable (and preferred) to remove polygon faces from objects that cannot be seen by the player. 
However, in VR games, players have much more freedom to look around, and this practice can sometimes lead to players being able to see things that they're not supposed to see.

 * **Which Type of Lighting to use** - You should always use **Static lighting** and **Lightmaps** when making a VR project... this is the cheapest option to render. 
If you need to use dynamic lighting, make sure to limit the amount of dynamic lights to as few as possible, and make sure that they never touch one another. 
If you have an outdoor scene, set your directional light to dynamic instead of stationary, and then turn on Cascaded Shadow Maps (CSM); adjusting the settings to be as simple as possible while still giving you shadows. 

 * **VR & VFX** - Some VFX tricks, like using [SubUV Textures](https://docs.unrealengine.com/latest/INT/Engine/Rendering/ParticleSystems/Reference/Modules/SubUV/index.html) to simulate fire or smoke, do not hold up very well when viewed in VR. 
In many cases you are going to need to use static meshes instead of 2D particles to simulate VFX's like explosions or smoke trails.  
Near field effects, or effects that happen very close to the camera, work well in VR, but only when the effects are made up of Static Mesh particles.

 * **VR & Transparency** - In 3D graphics, rendering transparency is extremely costly, because transparency will generally have to be re-evaluated per-frame to ensure that nothing has changed. 
Because of this re-evaluation, rendering Transparency in VR can be so costly, that its cost outweighs its benefits. 
However, to get around this issue, you can use the **DitherTemporalAA** Material Function. 
This Material Function will allow a Material to look like it is using transparency. Also, this will help you avoid common transparency issues, such as self-sorting.

	[REGION:lightbox]
	[![](VR_Dither_Trans_AA.png)(w:500)](VR_Dither_Trans_AA.png)
	[/REGION]

	[REGION:caption]
	Click for full image.
	[/REGION]

 * **Fake everything you can** - Finding clever ways to recreate expensive rendering options, like dynamic shadows or lighting, can be a huge win for hitting your performance goals in VR. 
In Showdown, having the characters cast dynamic shadows proved to be too expensive per-frame, which meant that dynamic shadows had to be cut from the project. 
However, this made the characters look like they were floating while moving. 
To fix this, fake blob shadows were introduced that could dynamically adjust their position and intensity based on how close the character was to an object in the world. 
This helped give the illusion that a character was casting shadows when they came close to the ground (or other objects).

	[region:lightbox]
	[![](VR_Fake_Shadow_Material.png)(w:1000)](VR_Fake_Shadow_Material.png)
	[/region]

	[region:caption]
	Click for full image.
	[/region]
[COMMENT:none]

## VR Blueprint Functions
 
 Throughout the Blueprint editor, you will find a number of different Blueprint nodes that can be used to interact with VR headsets and motion controllers. 
 Below, you will find a description of what each of these nodes are, and what they do.

### Head Mounted Display Blueprint Nodes

![](VR_HMD_BP_Nodes.png)
|Blueprint Node Name| Functionality | 
|---| --- |
Enable HMD|Switches to/from using HMD stereo rendering.|
Enable Low Persistence Mode|Switches between low and full persistence mode.|
Get Orientation And Position|Grabs the current orientation and position for the HMD.|
Get Positional Tracking Camera Parameters|If the HMD has a positional tracking camera, this will return the game-world location of the camera, as well as the parameters for the bounding region of the tracking camera. This allows an in-game representation of the legal positional tracking range. All values will be zeroed if the camera is not available, or if the HMD does not support it.|
Get Screen Percentage|Returns screen percentage to be used in VR mode.|
Get World to Meters Scale|Returns the World to Meters scale, which corresponds to the scale of the world as perceived by the player.|
Has Valid Tracking Position|If the HMD supports positional tracking, whether or not we are currently being tracked.|
Is Head Mounted Display Enabled|Returns whether or not we are currently using the head mounted display.|
Is In Low Persistence Mode| Returns _true_, if HMD is in low persistence mode; _false_ otherwise.|
Reset Orientation And Position| Resets orientation by setting roll and pitch to 0, assuming that current yaw is forward direction and assuming current position as a 'zero-point' (for position tracking).|
Set Clipping Planes| Sets the near and far clipping planes (NCP and FCP respectively) for stereo rendering. This is similar to the `stereo ncp = fcp` console command, but NCP and FCP set by this command will no be saved to the .INI file|
Set World to Meters Scale| Sets the World to Meters scale, which changes the scale of the world as perceived by the player.|

### Steam VR Blueprint Nodes

![](VR_Steam_VR_BP.png)
|Blueprint Node Name| Functionality | 
|---| --- |
|Get Hand Position and Orientation| Given a controller index and a hand, return the position and orientation of the controller.|
|Get Tracked Device Position and Orientation|Grabs the current orientation and position for the HMD.|
|Get Tracking Space| Gets the tracking space (for example, sitting or standing), which determines the location of the origin.|
|Get Valid Tracked Device Ids| Returns an array of the currently tracked device IDs.|
|Set Tracking Space| Sets the tracking space (for example, sitting or standing), changing which space (tracked) positions are returned to.|

[/COMMENT]
## Known VR Issues

Due to the manner in which HMD's work, some art techniques that are staples of Video Game development, no longer have the impact that they once did. 
Below, you will find a list of features that might not work as expected in VR, with possible workarounds to address this. 


* **Screen Space Reflections(SSR):** While SSR will still work in VR the reflections that they produce could have issues matching up to what it is reflecting in the world. Instead of using SSR use [Reflection Probes](Resources/Showcases/Reflections#reflectionenvironment) as they are much cheaper and do suffer less from reflection alignment issues.

**Normal Mapping Issues**

When viewing Normal maps on objects in VR, you will notice that they do not have the impact that they might have once had. 
This is because Normal mapping does not account for having a binocular display or motion parallax. 
Because of this, Normal maps will often come out looking flat when viewed with a VR device. 
However, that does not mean that you should not, or will not, need to use Normal maps; 
it just means that you need to more closely evaluate if the data you are trying to convey in the Normal map would be better off being made out of geometry. 
Below, you will find some different techniques that can be used in place of Normal maps. 

* **[Parallax Mapping](http://en.wikipedia.org/wiki/Parallax_mapping):** Parallax mapping takes Normal mapping to the next level, by accounting for depth cues that Normal mapping does not. A Parallax mapping shader can better display depth information, making objects appear to have more detail than they do. This is due to the fact that no matter what angle you look at, a Parallax map will always correct itself to show you the correct depth information from your view point. The best use of a Parallax map would be for cobblestone pathways and fine detail on surfaces. 

