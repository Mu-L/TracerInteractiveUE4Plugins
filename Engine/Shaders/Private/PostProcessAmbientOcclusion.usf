// Copyright Epic Games, Inc. All Rights Reserved.

/*=============================================================================
	PostprocessAmbientOcclusion.usf: To generate ambient occlusion as a postprocess
=============================================================================*/

#include "Common.ush"	
#include "PostProcessCommon.ush"				
#include "DeferredShadingCommon.ush"

// set by C++:
//
// 0:low / 1: medium / 2:high / 4:very high
// SHADER_QUALITY
//
// 0:no / 1:yes
// USE_AO_SETUP_AS_INPUT
//
// 0:no / 1:yes
// USE_UPSAMPLE

// Testing the GTAO Implementation between a heavy weight reference and an in game one
#define GTAO_REF 0

// Simplified optimized version of GTAO.
// The biggest difference here is the depth map is treated as an othographic projected height map rather than a perspective one. 
// This leads to differences in angles and fall off distances but generally the differences are minor. For extreme FOV cases this might be a problem.
#define GTAO_OPT 0

// This define enables the thickness heuristic which assu
#define GTAO_THICKNESS_HEURISTIC 1

// Define to Use Cosine Weighted Integral
#define GTAO_PROJECTED_NORMAL_WEIGHTING 0

// Define to Use Cosine Weighted Integral
#define GTAO_COSINE_WEIGHTED_INTEGRAL 1

// 0: classic with weighted sample, 1: don't normalize and adjust the formula to be simpler and faster - can look better and is cheaper (Alchemy like?)
#define OPTIMIZATION_O1 1

// 1:lowest quality, 2:medium , 3:high, more doesn't give too much (maybe HZB mip computations should `be adjusted)
//#define SAMPLE_STEPS 3

// 0:off / 1:show samples on the right side of the screen
#define DEBUG_LOOKUPS 0

// 0:off / 1:take into account scene normals in the computations
#define USE_NORMALS 1

// useful to remove high frequency dither pattern, not that needed with more sample
// 0:off (fast but dither pattern with low sample count), 1:non normal aware (half res look), 2:normal aware (slower), 3:normal and depth aware (slowest, doesn't add much)
//#define QUAD_MESSAGE_PASSING_BLUR 2

// ambient occlusion
// AO_SAMPLE_QUALITY = 0 : no AO sampling, only upsampling
// AO_SAMPLE_QUALITY = 1 : no dither/per pixel randomization
// AO_SAMPLE_QUALITY = 2 : efficient high frequency 4x4 pattern without jitter for TemporalAA
// AO_SAMPLE_QUALITY = 3 : efficient high frequency 4x4 pattern with jitter for TemporalAA

#if SHADER_QUALITY == 0
	// very low
	#define USE_SAMPLESET 1
	#define SAMPLE_STEPS 1
	#define QUAD_MESSAGE_PASSING_BLUR 0
#elif SHADER_QUALITY == 1
	// low
	#define USE_SAMPLESET 1
	#define SAMPLE_STEPS 1
	#define QUAD_MESSAGE_PASSING_BLUR 2
#elif SHADER_QUALITY == 2
	// medium
	#define USE_SAMPLESET 1
	#define SAMPLE_STEPS 2
	#define QUAD_MESSAGE_PASSING_BLUR 2
#elif SHADER_QUALITY == 3
	// high
	#define USE_SAMPLESET 1
	#define SAMPLE_STEPS 3
	#define QUAD_MESSAGE_PASSING_BLUR 0
#else // SHADER_QUALITY == 4
	// very high
	#define USE_SAMPLESET 3
	#define SAMPLE_STEPS 3
	#define QUAD_MESSAGE_PASSING_BLUR 0
#endif

#if QUAD_MESSAGE_PASSING_BLUR == 0
	#define QUAD_MESSAGE_PASSING_NORMAL 0
	#define QUAD_MESSAGE_PASSING_DEPTH 0
#elif QUAD_MESSAGE_PASSING_BLUR == 1
	#define QUAD_MESSAGE_PASSING_NORMAL 0
	#define QUAD_MESSAGE_PASSING_DEPTH 0
#elif QUAD_MESSAGE_PASSING_BLUR == 2
	#define QUAD_MESSAGE_PASSING_NORMAL 1
	#define QUAD_MESSAGE_PASSING_DEPTH 0
#elif QUAD_MESSAGE_PASSING_BLUR == 3
	#define QUAD_MESSAGE_PASSING_NORMAL 1
	#define QUAD_MESSAGE_PASSING_DEPTH 1
#endif

// 0:4 samples, 1:9 samples (only really noticable with dither usage ??)
//#define AO_UPSAMPLE_QUALITY 

#if USE_AO_SETUP_AS_INPUT == 1
	// lower resolution
	#define AO_SAMPLE_QUALITY 3
	#undef USE_SAMPLESET
	#define USE_SAMPLESET 3
	#define AO_UPSAMPLE_QUALITY 1
#else
	// full resolution is expensive, do lower quality
	#define AO_SAMPLE_QUALITY 3
	#define AO_UPSAMPLE_QUALITY 0
#endif

// 0: 1 point (for testing)
// 1: 3 points
// 2: more evenly spread (5 points - slightly faster, stronger effect, better with multiple levels?)
// 3: near the surface very large, softly fading out (6 points)
#if USE_SAMPLESET == 0
	#define SAMPLESET_ARRAY_SIZE 1
	static const float2 OcclusionSamplesOffsets[SAMPLESET_ARRAY_SIZE]=
	{
		// one sample, for testing
		float2(0.500, 0.500), 
	};
#elif USE_SAMPLESET == 1
	#define SAMPLESET_ARRAY_SIZE 3
	static const float2 OcclusionSamplesOffsets[SAMPLESET_ARRAY_SIZE]=
	{
		// 3 points distributed on the unit disc, spiral order and distance
		float2(0, -1.0f) * 0.43f, 
		float2(0.58f, 0.814f) * 0.7f, 
		float2(-0.58f, 0.814f) 
	};
#elif USE_SAMPLESET == 2
	#define SAMPLESET_ARRAY_SIZE 5
	static const float2 OcclusionSamplesOffsets[SAMPLESET_ARRAY_SIZE]=
	{
		// 5 points distributed on a ring
		float2(0.156434, 0.987688),
		float2(0.987688, 0.156434)*0.9,
		float2(0.453990, -0.891007)*0.8,
		float2(-0.707107, -0.707107)*0.7,
		float2(-0.891006, 0.453991)*0.65,
	};
#else // USE_SAMPLESET == 3
	#define SAMPLESET_ARRAY_SIZE 6
	static const float2 OcclusionSamplesOffsets[SAMPLESET_ARRAY_SIZE]=
	{
		// 6 points distributed on the unit disc, spiral order and distance
		float2(0.000, 0.200), 
		float2(0.325, 0.101), 
		float2(0.272, -0.396), 
		float2(-0.385, -0.488), 
		float2(-0.711, 0.274), 
		float2(0.060, 0.900) 
	};
#endif // USE_SAMPLESET
	



// [0]: .x:AmbientOcclusionPower, .y:AmbientOcclusionBias/BiasDistance, .z:1/AmbientOcclusionDistance, .w:AmbientOcclusionIntensity
// [1]: .xy:ViewportUVToRandomUV, .z:AORadiusInShader, .w:Ratio
// [2]: .x:ScaleFactor(e.g. 4 if current RT is a quarter in size), .y:InvThreshold, .z:ScaleRadiusInWorldSpace(0:VS/1:WS), .w:MipBlend
// [3]: .xy:TemporalAARandomOffset, .z:StaticFraction, .w: InvTanHalfFov
// [4]: .x:Multipler for FadeDistance/Radius, .y:Additive for FadeDistance/Radius, .z:clamped HzbStepMipLevelFactorValue .w: unused
// [5]: .xy: ViewRectSize (for AsyncCompute where UniformBuffers don't work yet)  .zw ViewRect Min.xy
float4 ScreenSpaceAOParams[6];

// needed to prevent AO seam near 16 bit float maximum, this feactor pushed the problem far out and it seems to not have a visual degradion nearby
const static float Constant_Float16F_Scale =  4096.0f * 32.0f;

// only for MainSetupPS()
// .x:ScaleFactor(e.g. 4 if current RT is a quarter in size), .y:InvThreshold, .zw: unused
float4 AmbientOcclusionSetupParams;

// 
float4 NoiseScale;

/** RGBA8 linear texture containing random normals */
Texture2D RandomNormalTexture;
SamplerState RandomNormalTextureSampler;

// .xy:mul .zw:add   scale and bias to convert between BufferUV and HZB-UV
float4 HZBRemapping;

// could be moved to a more central spot
// @param ScreenPos -1 .. 1
float3 ReconstructCSPos(float SceneDepth, float2 ScreenPos)
{
	return float3(ScreenPos * SceneDepth, SceneDepth);
}

// could be moved to a more central spot
float2 ReconstructSSPosFromCS(float3 In)
{
	return In.xy / In.z;
}

// could be moved to a more central spot
// can be optimized
// @param InputSize e.g. PostprocessInput0Size
float2 ScreenPosToUV(float2 ScreenPos, float4 InputSize)
{
	return (ScreenPos * ScreenPosToPixel.xy + ScreenPosToPixel.zw + 0.5f) * InputSize.zw;
}

// 0: not similar .. 1:very similar
float ComputeDepthSimilarity(float DepthA, float DepthB, float TweakScale)
{
	return saturate(1 - abs(DepthA - DepthB) * TweakScale);
}

float TakeSmallerAbsDelta(float left, float mid, float right)
{
	float a = mid - left;
	float b = right - mid;

	return (abs(a) < abs(b)) ? a : b;
}

// could use ddx,ddy but that would have less quality and would nto work fo ComputeShaders
// @return not normalized normal in world space
float3 ReconstructNormalFromDepthBuffer(float4 SvPosition)
{
	// could use a modified version of GatherSceneDepth later on
	float DeviceZ = LookupDeviceZ(SvPositionToBufferUV(SvPosition + float4(0, 0, 0, 0)));
	float DeviceZLeft = LookupDeviceZ(SvPositionToBufferUV(SvPosition + float4(-1, 0, 0, 0)));
	float DeviceZTop = LookupDeviceZ(SvPositionToBufferUV(SvPosition + float4(0, -1, 0, 0)));
	float DeviceZRight = LookupDeviceZ(SvPositionToBufferUV(SvPosition + float4(1, 0, 0, 0)));
	float DeviceZBottom = LookupDeviceZ(SvPositionToBufferUV(SvPosition + float4(0, 1, 0, 0)));

	// Favor the surfae we are looking at. Simiar to: http://www.humus.name/index.php?page=3D&ID=84
	float DeviceZDdx = TakeSmallerAbsDelta(DeviceZLeft, DeviceZ, DeviceZRight);
	float DeviceZDdy = TakeSmallerAbsDelta(DeviceZTop, DeviceZ, DeviceZBottom);

	// can be optimized, is not fully centered but that should not matter much
	float3 Mid =	SvPositionToTranslatedWorld(float4(SvPosition.xy + float2(0, 0), DeviceZ, 1));
	float3 Right =	SvPositionToTranslatedWorld(float4(SvPosition.xy + float2(1, 0), DeviceZ + DeviceZDdx, 1)) - Mid;
	float3 Down =	SvPositionToTranslatedWorld(float4(SvPosition.xy + float2(0, 1), DeviceZ + DeviceZDdy, 1)) - Mid;

	return cross(Right, Down);
}

// downsample the input of the ambient occlusion pass for better performance, can take input from setup or another downsample pass
void MainSetupPS(in noperspective float4 UVAndScreenPos : TEXCOORD0, float4 SvPosition : SV_POSITION, out float4 OutColor0 : SV_Target0)
{
	float2 ViewPortSize = ScreenSpaceAOParams[5].xy;
	float2 InUV = UVAndScreenPos.xy;

#if INITIAL_PASS == 1
	float2 Pixel = PostprocessInput0Size.zw;
#else
	float2 Pixel = PostprocessInput1Size.zw;
#endif

	// can be optimized
	float2 UV[4];
	UV[0] = InUV + float2(-0.5f, -0.5f) * Pixel;
	UV[1] = min(InUV + float2( 0.5f, -0.5f) * Pixel, View.BufferBilinearUVMinMax.zw);
	UV[2] = min(InUV + float2(-0.5f,  0.5f) * Pixel, View.BufferBilinearUVMinMax.zw);
	UV[3] = min(InUV + float2( 0.5f,  0.5f) * Pixel, View.BufferBilinearUVMinMax.zw);

	float4 Samples[4];
	
	UNROLL for(uint i = 0; i < 4; ++i)
	{
#if COMPUTE_SHADER || FORWARD_SHADING
		// Async compute and forward shading don't have access to the gbuffer.
		Samples[i].rgb = normalize(ReconstructNormalFromDepthBuffer(float4(UV[i] * ViewPortSize, SvPosition.zw))) * 0.5f + 0.5f;
#else
		Samples[i].rgb = GetGBufferData(UV[i], true).WorldNormal * 0.5f + 0.5f;
#endif
		Samples[i].a = CalcSceneDepth(UV[i]);
	}
	
	float MaxZ = max( max(Samples[0].a, Samples[1].a), max(Samples[2].a, Samples[3].a));

	float4 AvgColor = 0.0f;
	if (USE_NORMALS)
	{
		AvgColor = 0.0001f;

		float InvThreshold = AmbientOcclusionSetupParams.y;
		{
			UNROLL for(uint i = 0; i < 4; ++i)
			{
				AvgColor += float4(Samples[i].rgb, 1) * ComputeDepthSimilarity(Samples[i].a, MaxZ, InvThreshold);
			}
			AvgColor.rgb /= AvgColor.w;
		}
	}

	OutColor0 = float4(AvgColor.rgb, MaxZ / Constant_Float16F_Scale);
}

float GetDepthFromAOInput(float2 UV)
{	
#if USE_AO_SETUP_AS_INPUT
	// low resolution
	return Texture2DSample(PostprocessInput0, PostprocessInput0Sampler, UV).a * Constant_Float16F_Scale;
#else
	// full resolution 
	return CalcSceneDepth(UV);
#endif
}

// @return can be 0,0,0 if we don't have a good input normal
float3 GetWorldSpaceNormalFromAOInput(float2 UV, float4 SvPosition)
{
	float3 WorldNormal = 0;

	if (USE_NORMALS)
	{
	#if USE_AO_SETUP_AS_INPUT
		// Low resolution normal computed in the setup (downscaled) pass.
		WorldNormal = Texture2DSample(PostprocessInput0, PostprocessInput0Sampler, frac(UV)).xyz * 2 - 1;
	#elif COMPUTE_SHADER || FORWARD_SHADING
		// Async compute and forward shading don't have access to the gbuffer.
		WorldNormal = ReconstructNormalFromDepthBuffer(SvPosition);
	#else
		// Otherwise sample Gbuffer normals if the shader model has normals.
		FGBufferData GBuffer = GetGBufferData(UV, false);
		if( GBuffer.ShadingModelID != SHADINGMODELID_HAIR )
		{
			WorldNormal = GetGBufferData(UV, false).WorldNormal;
		}
	#endif
	}

	return WorldNormal;
}

float4 ComputeUpsampleContribution(float SceneDepth, float2 InUV, float3 CenterWorldNormal)
{
	// can be optimized
#if AO_UPSAMPLE_QUALITY == 0
	const int SampleCount = 4;
	float2 UV[SampleCount];

	UV[0] = InUV + float2(-0.5f,  0.5f) *  PostprocessInput2Size.zw;
	UV[1] = InUV + float2( 0.5f,  0.5f) *  PostprocessInput2Size.zw;
	UV[2] = InUV + float2(-0.5f, -0.5f) *  PostprocessInput2Size.zw;
	UV[3] = InUV + float2( 0.5f, -0.5f) *  PostprocessInput2Size.zw;
#else // AO_UPSAMPLE_QUALITY == 0
	const int SampleCount = 9;
	float2 UV[SampleCount];

	UV[0] = InUV + float2( -1, -1) *  PostprocessInput2Size.zw;
	UV[1] = InUV + float2(  0, -1) *  PostprocessInput2Size.zw;
	UV[2] = InUV + float2(  1, -1) *  PostprocessInput2Size.zw;
	UV[3] = InUV + float2( -1,  0) *  PostprocessInput2Size.zw;
	UV[4] = InUV + float2(  0,  0) *  PostprocessInput2Size.zw;
	UV[5] = InUV + float2(  1,  0) *  PostprocessInput2Size.zw;
	UV[6] = InUV + float2( -1,  1) *  PostprocessInput2Size.zw;
	UV[7] = InUV + float2(  0,  1) *  PostprocessInput2Size.zw;
	UV[8] = InUV + float2(  1,  1) *  PostprocessInput2Size.zw;
#endif // AO_UPSAMPLE_QUALITY == 0

	// to avoid division by 0
	float SmallValue = 0.0001f;

	// we could weight the samples better but tests didn't show much difference
	float WeightSum = SmallValue;
	float4 Ret = float4(SmallValue,0,0,0);

	float InvThreshold = ScreenSpaceAOParams[2].y;
	float MinIteration = 1.0f;

	UNROLL for(int i = 0; i < SampleCount; ++i)
	{
		float4 SampleValue = Texture2DSample(PostprocessInput2, PostprocessInput2Sampler, UV[i]);

		MinIteration = min(MinIteration, SampleValue.g);

		float4 NormalAndSampleDepth = Texture2DSample(PostprocessInput1, PostprocessInput1Sampler, UV[i]);
		float SampleDepth = NormalAndSampleDepth.a * Constant_Float16F_Scale;

		// when tweaking this constant look for crawling pattern at edges
		float Weight = ComputeDepthSimilarity(SampleDepth, SceneDepth, 0.003f);

		if (USE_NORMALS)
		{
			float3 LocalWorldNormal = NormalAndSampleDepth.xyz*2-1;
			Weight *= saturate(dot(LocalWorldNormal, CenterWorldNormal));
		}

		// todo: 1 can be put into the input to save an instruction
		Ret += float4(SampleValue.rgb, 1) * Weight;
		WeightSum += Weight;
	}

	Ret /= WeightSum;
	Ret.g = MinIteration;

	return Ret;
}

// to blend between upsampled and current pass data
float ComputeLerpFactor()
{
	// set up on C++ side
	float MipBlend = ScreenSpaceAOParams[2].w;

	float AOLerpFactor = MipBlend;

#if AO_SAMPLE_QUALITY == 0
	// we have no AO, we only use the upsampled data
	AOLerpFactor = 1.0f;
#endif

#if USE_UPSAMPLE == 0
	// if there is no former pass we cannot use the data
	AOLerpFactor = 0.0f;
#endif
	
	return AOLerpFactor;
}

// @return NormAngle means 0..1 is actually 0..PI
float acosApproxNormAngle(float x)
{
	// todo: expose
	// 1: is a good linear approximation, 0.9f seems to look good
	float ContrastTweak = 0.9f;

	// correct: acos(x) / PI
	// linear approximation: saturate((1 - x) * 0.5f);
	// pretty good approximation with contrast tweak
	return saturate((1 - x) * 0.5f * ContrastTweak);
}

// @param In -1..1
float2 ScreenPosToHZBUV(float2 In)
{
	// MAD instruction
	return HZBRemapping.xy * In + HZBRemapping.zw;
}

// @return float3(InvNormAngleL, InvNormAngleR, Weight)
float3 WedgeWithNormal(float2 ScreenSpacePosCenter, float2 InLocalRandom, float3 InvFovFix, float3 ViewSpacePosition, float3 ScaledViewSpaceNormal, float InvHaloSize, float MipLevel)
{
	float2 ScreenSpacePosL = ScreenSpacePosCenter + InLocalRandom;
	float2 ScreenSpacePosR = ScreenSpacePosCenter - InLocalRandom;

	float TexL = Texture2DSampleLevel( PostprocessInput3, PostprocessInput3Sampler, ScreenPosToHZBUV(ScreenSpacePosL), MipLevel).r;
	float TexR = Texture2DSampleLevel( PostprocessInput3, PostprocessInput3Sampler, ScreenPosToHZBUV(ScreenSpacePosR), MipLevel).r;

	float AbsL = ConvertFromDeviceZ(TexL);
	float AbsR = ConvertFromDeviceZ(TexR);

	float3 SamplePositionL = ReconstructCSPos(AbsL, ScreenSpacePosL);
	float3 SamplePositionR = ReconstructCSPos(AbsR, ScreenSpacePosR);

	float3 DeltaL = (SamplePositionL - ViewSpacePosition) * InvFovFix;
	float3 DeltaR = (SamplePositionR - ViewSpacePosition) * InvFovFix;
		
#if OPTIMIZATION_O1
	float InvNormAngleL = saturate(dot(DeltaL, ScaledViewSpaceNormal) / dot(DeltaL, DeltaL));
	float InvNormAngleR = saturate(dot(DeltaR, ScaledViewSpaceNormal) / dot(DeltaR, DeltaR));
	float Weight = 1;
#else
	float InvNormAngleL = saturate(dot(DeltaL, ScaledViewSpaceNormal) * rsqrt(dot(DeltaL, DeltaL)));
	float InvNormAngleR = saturate(dot(DeltaR, ScaledViewSpaceNormal) * rsqrt(dot(DeltaR, DeltaR)));

	float Weight = 
		  saturate(1.0f - length(DeltaL) * InvHaloSize)
		* saturate(1.0f - length(DeltaR) * InvHaloSize);
#endif

	return float3(InvNormAngleL, InvNormAngleR, Weight);
}



// @return float2(InvNormAngle, Weight)
float2 WedgeNoNormal(float2 ScreenSpacePosCenter, float2 InLocalRandom, float3 InvFovFix, float3 ViewSpacePosition, float InvHaloSize, float MipLevel)
{
	float2 ScreenSpacePosL = ScreenSpacePosCenter + InLocalRandom;
	float2 ScreenSpacePosR = ScreenSpacePosCenter - InLocalRandom;

	float TexL = Texture2DSampleLevel( PostprocessInput3, PostprocessInput3Sampler, ScreenPosToHZBUV(ScreenSpacePosL), MipLevel).r;
	float TexR = Texture2DSampleLevel( PostprocessInput3, PostprocessInput3Sampler, ScreenPosToHZBUV(ScreenSpacePosR), MipLevel).r;

	float AbsL = ConvertFromDeviceZ(TexL);
	float AbsR = ConvertFromDeviceZ(TexR);
	
	float3 SamplePositionL = ReconstructCSPos(AbsL, ScreenSpacePosL);
	float3 SamplePositionR = ReconstructCSPos(AbsR, ScreenSpacePosR);
	
	float3 DeltaL = (SamplePositionL - ViewSpacePosition) * InvFovFix;
	float3 DeltaR = (SamplePositionR - ViewSpacePosition) * InvFovFix;

	float WeightLeft;
	float3 SamplePositionLeft;
	{
		WeightLeft = 1;

#if !OPTIMIZATION_O1
		WeightLeft = saturate(1.0f - length(DeltaL) * InvHaloSize);
#endif
	}

	float WeightRight;
	float3 SamplePositionRight;
	{	
		WeightRight = 1;

#if !OPTIMIZATION_O1
		WeightRight = saturate(1.0f - length(DeltaR) * InvHaloSize);
#endif
	}


	float FlatSurfaceBias = 5.0f;

	float left = ViewSpacePosition.z - AbsL;
	float right = ViewSpacePosition.z - AbsR;

	// OptionA: accurate angle computation
	float NormAngle = acosApproxNormAngle( dot(DeltaL, DeltaR) / sqrt(length2(DeltaL) * length2(DeltaR)));
	// OptionB(fade out in near distance): float NormAngle = acosApproxNormAngle( (- left - right) * 20);
	// OptionC(look consistent but more noisy, should be much faster): float NormAngle = 0;


	// not 100% correct but simple
	// bias is needed to avoid flickering on almost perfectly flat surfaces
	//	    if((leftAbs  + rightAbs) * 0.5f > SceneDepth - 0.0001f)
	if(left + right < FlatSurfaceBias)
	{
		// fix concave case
		NormAngle = 1;
	}

	// to avoid halos around objects
	float Weight = 1;
				
	float InvAmbientOcclusionDistance = ScreenSpaceAOParams[0].z;
	float ViewDepthAdd = 1.0f - ViewSpacePosition.z * InvAmbientOcclusionDistance;

	Weight *= saturate(SamplePositionL.z * InvAmbientOcclusionDistance + ViewDepthAdd);
	Weight *= saturate(SamplePositionR.z * InvAmbientOcclusionDistance + ViewDepthAdd);

//	return float2(1 - NormAngle, (WeightLeft + WeightRight) * 0.5f);
	return float2((1-NormAngle) / (Weight + 0.001f), Weight);
}

float3 ReconstructNormal(float2 In)
{
	return float3(In, sqrt(1 - dot(In, In)));
}


// @param ScreenSpacePos -1..1
// @return 1 if inside the center, 0 if outside
float ComputeSampleDebugMask(float2 ScreenSpacePos, float MipLevel)
{
	ScreenSpacePos.x -= 0.5f;

	ScreenSpacePos.y = frac(ScreenSpacePos.y) - 0.5f;

	float2 ViewPortSize = ScreenSpaceAOParams[5].xy;
	int2 PixelOffsetToCenter = int2(ScreenSpacePos * ViewPortSize * 0.5f);

	float d = length(PixelOffsetToCenter);

	// revisit this
	float radius = 12.0f;

	// hard
	return d < radius * exp2(MipLevel);
	// soft
//	return saturate(1 - d / (radius * exp2(MipLevel)));
}

float ComputeMipLevel(int sampleid, int step)
{
	float SamplePos = (sampleid + 0.5f) / SAMPLESET_ARRAY_SIZE;

	float HzbStepMipLevelFactorValue = ScreenSpaceAOParams[4].z;
	// use a constant to get better performance
	//float HzbStepMipLevelFactorValue = 0.5f;
//	float HzbStepMipLevelFactorValue = 1;

	float Scale = (step + 1) / (float)SAMPLE_STEPS;

//	return log2(1.0f + HzbStepMipLevelFactorValue * Scale * SamplePos);
	return log2(HzbStepMipLevelFactorValue * Scale * SamplePos);
}

// the main pixel shader that computes ambient occlusion
void MainPSandCS(in float4 UVAndScreenPos, float4 SvPosition, out float4 OutColor)
{
	OutColor = 0;

	// the following constants as set up on C++ side
	float AmbientOcclusionPower = ScreenSpaceAOParams[0].x;
	float Ratio = ScreenSpaceAOParams[1].w;
	float AORadiusInShader = ScreenSpaceAOParams[1].z;
	float InvAmbientOcclusionDistance = ScreenSpaceAOParams[0].z;
	float AmbientOcclusionIntensity = ScreenSpaceAOParams[0].w;
	float2 ViewportUVToRandomUV = ScreenSpaceAOParams[1].xy;
	float AmbientOcclusionBias = ScreenSpaceAOParams[0].y;
	float ScaleFactor = ScreenSpaceAOParams[2].x;
	float ScaleRadiusInWorldSpace = ScreenSpaceAOParams[2].z;

	float2 UV = UVAndScreenPos.xy;
	float2 ScreenPos = UVAndScreenPos.zw;

	float InvTanHalfFov = ScreenSpaceAOParams[3].w;
	float3 FovFix = float3(InvTanHalfFov, Ratio * InvTanHalfFov, 1);
	float3 InvFovFix = 1.0f / FovFix;

	float SceneDepth = GetDepthFromAOInput(UV);
	float3 WorldNormal = GetWorldSpaceNormalFromAOInput(UV, SvPosition);

	// can be NaN if WorldNormal=0,0,0 which happens when !USE_NORMALS
	float3 ViewSpaceNormal = normalize(mul(WorldNormal, (float3x3)View.TranslatedWorldToView));

	float3 ViewSpacePosition = ReconstructCSPos(SceneDepth, ScreenPos);

	float ActualAORadius = AORadiusInShader * lerp(SceneDepth, 1, ScaleRadiusInWorldSpace);

	// Add bias after fixup (causes minor banding - not needed with larger radius)
	if (USE_NORMALS)
	{
		ViewSpacePosition += AmbientOcclusionBias * SceneDepth * ScaleFactor * (ViewSpaceNormal * FovFix);
	}

	float2 WeightAccumulator = 0.0001f;
	
#if AO_SAMPLE_QUALITY != 0
	// no SSAO in this pass, only upsampling

#if AO_SAMPLE_QUALITY == 1
	// no 4x4 randomization
	float2 RandomVec = float2(0, 1) * ActualAORadius;
	{
#elif AO_SAMPLE_QUALITY == 2
	// extract one of 16 base vectors (rotation and scale) from a texture that repeats 4x4
	float2 RandomVec = (Texture2DSample(RandomNormalTexture, RandomNormalTextureSampler, UV * ViewportUVToRandomUV).rg * 2 - 1) * ActualAORadius;
	{
#else // AO_SAMPLE_QUALITY == 3
	// extract one of 16 base vectors (rotation and scale) from a texture that repeats 4x4, changing over time if TemporalAA is enabled

	// jitter each frame a bit to get higher quality over multiple frames (only if TemporalAA is enabled), can cause ghosting effects
	const float2 TemporalOffset = ScreenSpaceAOParams[3].xy;

	// if the feature is enabled and right side of screen
	const bool bDebugLookups = DEBUG_LOOKUPS && ViewSpacePosition.x > 0;

	float2 RandomVec = (Texture2DSample(RandomNormalTexture, RandomNormalTextureSampler, TemporalOffset + UV * ViewportUVToRandomUV).rg * 2 - 1) * ActualAORadius;
	{
#endif // AO_SAMPLE_QUALITY == 

		if(bDebugLookups && ViewSpacePosition.y > 0)
		{
			// top sample are not per pixel rotated
			RandomVec = float2(0, 1) * ActualAORadius;
		}

		float2 FovFixXY = FovFix.xy * (1.0f / ViewSpacePosition.z);
		float4 RandomBase = float4(RandomVec, -RandomVec.y, RandomVec.x) * float4(FovFixXY, FovFixXY);

		float2 ScreenSpacePos = ViewSpacePosition.xy / ViewSpacePosition.z;

		// to debug the input depth
//		OutColor = GetDepthForSSAO(ScreenSpacePos, 0); return;
		// to debug the reconstructed normal
//		OutColor = ReconstructedViewSpaceNormal.z; return;

		// .x means for very anisotropic viewports we scale by x
		float InvHaloSize = 1.0f / (ActualAORadius * FovFixXY.x * 2);

		float3 ScaledViewSpaceNormal = ViewSpaceNormal;

#if OPTIMIZATION_O1
		ScaledViewSpaceNormal *= 0.08f * lerp(SceneDepth, 1000, ScaleRadiusInWorldSpace);
#endif

		UNROLL for(int i = 0; i < SAMPLESET_ARRAY_SIZE; ++i)
		{
			// -1..1
			float2 UnrotatedRandom = OcclusionSamplesOffsets[i].xy;

			float2 LocalRandom = (UnrotatedRandom.x * RandomBase.xy + UnrotatedRandom.y * RandomBase.zw);

			if (bDebugLookups)
			{
				UNROLL for(uint step = 0; step < SAMPLE_STEPS; ++step)
				{
					float Scale = (step + 1) / (float)SAMPLE_STEPS;
					float MipLevel = ComputeMipLevel(i, step);
					float2 ScaledLocalRandom = Scale * LocalRandom;
					
					WeightAccumulator += float2(ComputeSampleDebugMask(ScreenSpacePos + ScaledLocalRandom, MipLevel), 1.0f);
					WeightAccumulator += float2(ComputeSampleDebugMask(ScreenSpacePos - ScaledLocalRandom, MipLevel), 1.0f);
				}
			}
			else if (USE_NORMALS)
			{
				float3 LocalAccumulator = 0;

				UNROLL for(uint step = 0; step < SAMPLE_STEPS; ++step)
				{
					// constant at run time
					float Scale = (step + 1) / (float)SAMPLE_STEPS;
					// constant at run time (higher is better for texture cache / performance, lower is better quality
					float MipLevel = ComputeMipLevel(i, step);

					float3 StepSample = WedgeWithNormal(ScreenSpacePos, Scale * LocalRandom, InvFovFix, ViewSpacePosition, ScaledViewSpaceNormal, InvHaloSize, MipLevel);

					// combine horizon samples
					LocalAccumulator = lerp(LocalAccumulator, float3(max(LocalAccumulator.xy, StepSample.xy), 1), StepSample.z);
				}

				// Square(): the area scales quadratic with the angle - it gets a bit darker
				WeightAccumulator += float2(Square(1 - LocalAccumulator.x) * LocalAccumulator.z, LocalAccumulator.z);
				WeightAccumulator += float2(Square(1 - LocalAccumulator.y) * LocalAccumulator.z, LocalAccumulator.z);
				// cheaper? Could move 1 - out
				// WeightAccumulator += float2(1 - LocalAccumulator.x, LocalAccumulator.y);
			}
			else // Case with no normals
			{
				float2 LocalAccumulator = 0;

				UNROLL for(uint step = 0; step < SAMPLE_STEPS; ++step)
				{
					// constant at run time
					float Scale = (step + 1) / (float)SAMPLE_STEPS;
					// constant at run time (higher is better for texture cache / performance, lower is better quality
					float MipLevel = ComputeMipLevel(i, step);

					float2 StepSample = WedgeNoNormal(ScreenSpacePos, Scale * LocalRandom, InvFovFix, ViewSpacePosition, InvHaloSize, MipLevel);

					// combine horizon samples
					LocalAccumulator = lerp(LocalAccumulator, float2(max(LocalAccumulator.x, StepSample.x), 1), StepSample.y);
				}

				// Square(): the area scales quadratic with the angle - it gets a bit darker
				WeightAccumulator += float2(Square(1 - LocalAccumulator.x) * LocalAccumulator.y, LocalAccumulator.y);

			}
		}
	}

#endif // #if AO_SAMPLE_QUALITY == 0


	OutColor.r = WeightAccumulator.x / WeightAccumulator.y;
	OutColor.gb = float2(0, 0);

	if(!bDebugLookups)
	{
#if COMPUTE_SHADER || FORWARD_SHADING
		// In compute, Input1 and Input2 are not necessarily valid.
		float4 Filtered = 1;
#else
		float4 Filtered = ComputeUpsampleContribution(SceneDepth, UV, WorldNormal);
#endif
		// recombined result from multiple resolutions
		OutColor.r = lerp(OutColor.r, Filtered.r, ComputeLerpFactor());
	}

#if !USE_AO_SETUP_AS_INPUT
	if(!bDebugLookups)
	{
		// full res

		// soft fade out AO in the distance
		{
			float Mul = ScreenSpaceAOParams[4].x;
			float Add = ScreenSpaceAOParams[4].y;
			OutColor.r = lerp(OutColor.r, 1, saturate(SceneDepth * Mul + Add));
		}

		// user adjust AO
		// abs() to prevent shader warning
		OutColor.r = 1 - (1 - pow(abs(OutColor.r), AmbientOcclusionPower)) * AmbientOcclusionIntensity;

		// we output in a single alpha channel
		OutColor = OutColor.r;
	}
	else
	{
		OutColor.r = pow(1 - OutColor.r, 16);	// constnt is tweaked with radius and sample count
	}
#endif

	// we don't support ddx_fine() for SM4
#if !COMPUTE_SHADER && QUAD_MESSAGE_PASSING_BLUR > 0 && FEATURE_LEVEL >= FEATURE_LEVEL_SM5
	{
		// .x: AO output, .y:SceneDepth .zw:view space normal
		float4 CenterPixel = float4(OutColor.r, SceneDepth, normalize(ViewSpaceNormal).xy); 

		float4 dX = ddx_fine(CenterPixel);
		float4 dY = ddy_fine(CenterPixel);

		int2 Mod = (uint2)(SvPosition.xy) % 2;

		float4 PixA = CenterPixel;
		float4 PixB = CenterPixel - dX * (Mod.x * 2 - 1);
		float4 PixC = CenterPixel - dY * (Mod.y * 2 - 1);

		float WeightA = 1.0f;
		float WeightB = 1.0f;
		float WeightC = 1.0f;

#if QUAD_MESSAGE_PASSING_NORMAL
		const float NormalTweak = 4.0f;
		float3 NormalA = ReconstructNormal(PixA.zw);
		float3 NormalB = ReconstructNormal(PixB.zw);
		float3 NormalC = ReconstructNormal(PixC.zw);
		WeightB *= saturate(pow(saturate(dot(NormalA, NormalB)), NormalTweak));
		WeightC *= saturate(pow(saturate(dot(NormalA, NormalC)), NormalTweak));
#endif

#if QUAD_MESSAGE_PASSING_DEPTH
		const float DepthTweak = 1;
		float InvDepth = 1.0f / PixA.y;
		WeightB *= 1 - saturate(abs(1 - PixB.y * InvDepth) * DepthTweak);
		WeightC *= 1 - saturate(abs(1 - PixC.y * InvDepth) * DepthTweak);
#endif

		// + 1.0f to avoid div by 0
		float InvWeightABC = 1.0f / (WeightA + WeightB + WeightC);

		WeightA *= InvWeightABC;
		WeightB *= InvWeightABC;
		WeightC *= InvWeightABC;

		OutColor = WeightA * PixA.x + WeightB * PixB.x + WeightC * PixC.x;
		// visualize where we don't want to fade
//		OutColor = (WeightA - 0.333f) / 0.666f;
	}
#endif
}

void MainPS(in noperspective float4 UVAndScreenPos : TEXCOORD0, float4 SvPosition : SV_POSITION, out float4 OutColor : SV_Target0)
{
	MainPSandCS(UVAndScreenPos, SvPosition, OutColor);	
}

#if COMPUTE_SHADER
/** Output target. In compute, this is a single value buffer. */
RWTexture2D<float> OutTexture;
[numthreads(THREADGROUP_SIZEX, THREADGROUP_SIZEY, 1)]
void MainCS(
	uint2 GroupId : SV_GroupID,
	uint2 DispatchThreadId : SV_DispatchThreadID,
	uint2 GroupThreadId : SV_GroupThreadID) 
{
	float ScaleFactor = ScreenSpaceAOParams[2].x;
	
	int2 PixelPos = DispatchThreadId + ScreenSpaceAOParams[5].zw; 
	float2 PixelCenter = (float2)PixelPos + float2(0.5, 0.5);
	
	// todo: move to a function
	float4 SvPosition = float4(PixelCenter, 0, 0) * ScaleFactor;	
	float2 BufferUV = SvPositionToBufferUV(SvPosition);
	SvPosition.z = LookupDeviceZ(BufferUV);
	// todo: investigate
//  SvPosition.w = ConvertFromDeviceZ(SvPosition.z);
	SvPosition.w = 1;

	float4 OutColor = 1;

	// Test for early exit with out of depth bound.
	float SceneDepth = ConvertFromDeviceZ(SvPosition.z);
	float FadeMul = ScreenSpaceAOParams[4].x;
	float FadeAdd = ScreenSpaceAOParams[4].y;
	BRANCH
	if (SceneDepth * FadeMul + FadeAdd < 1)
	{
		MainPSandCS(float4(BufferUV, SvPositionToScreenPosition(SvPosition).xy), SvPosition, OutColor);
	}

	// Here we could optimized for coalessing writes but that might not be the performance bottleneck.
	// We should rather optimized for best texture cache performance.
	// http://on-demand.gputechconf.com/gtc/2010/presentations/S12312-DirectCompute-Pre-Conference-Tutorial.pdf
	OutTexture[PixelPos] = OutColor.r;
}

// xy - output rect min
// zw - output rect width and height
float4 SSAOSmoothParams;
RWTexture2D<float> SSAOSmoothResult;

[numthreads(THREADGROUP_SIZEX, THREADGROUP_SIZEY, 1)]
void MainSSAOSmoothCS(
	uint2 GroupId : SV_GroupID,
	uint2 DispatchThreadId : SV_DispatchThreadID,
	uint2 GroupThreadId : SV_GroupThreadID)
{
	BRANCH
	if (any(DispatchThreadId >= (uint2)SSAOSmoothParams.zw))
	{
		return;
	}

	uint2 DestPixelPos = SSAOSmoothParams.xy + DispatchThreadId;
	float2 SampleUV = DestPixelPos * PostprocessInput0Size.zw;

	// Use a 4x4 box filter because the random texture is tiled 4x4
	float Result;
	Result = PostprocessInput0.SampleLevel(PostprocessInput0Sampler, SampleUV, 0).r;
	Result += PostprocessInput0.SampleLevel(PostprocessInput0Sampler, SampleUV, 0, int2(2, 0)).r;
	Result += PostprocessInput0.SampleLevel(PostprocessInput0Sampler, SampleUV, 0, int2(0, 2)).r;
	Result += PostprocessInput0.SampleLevel(PostprocessInput0Sampler, SampleUV, 0, int2(2, 2)).r;

	SSAOSmoothResult[DestPixelPos] = Result * 0.25;
}
#endif

#if GTAO_REF

#define GTAO_NUMROTS  32
#define GTAO_NUMTAPS  64

#else

#define GTAO_NUMROTS  1

#if SHADER_QUALITY == 0
	// very low
	#define GTAO_NUMTAPS 6
#elif SHADER_QUALITY == 1
	// low
	#define GTAO_NUMTAPS 8
#elif SHADER_QUALITY == 2
	// medium
	#define GTAO_NUMTAPS 10
#elif SHADER_QUALITY == 3
	// high
	#define GTAO_NUMTAPS 20
#else // SHADER_QUALITY == 4
	// very high
	#define GTAO_NUMTAPS 35
#endif
#endif

float4 GTAOParams[4];
// [0] - { cos(TemporalAngle), sin(TemporalAngle), TemporalOffset, FrameTemporalOffset}
// [1] - { FrameNumber, Thicknessblend, unused, unused}
// [2] - { TargetSizeX, TargetSizeY, 1.0/TargetSizeX, 1.0f/TargetSizeY}
// [3] - { FallOffStart, FallOffEnd, FalloffScale, FalloffBias}

struct FalloffParams
{
	float Start;
	float End;
	float EndSq;
	float Scale;
	float Bias;
	uint  MaxTaps;
};


// Get the parameters for the fall off and how many taps we must travel before we are guaranteed to hit it. 
FalloffParams ComputeFalloffParams(float ZDist)
{
	FalloffParams params;

	// get the distance at which the 
	params.Start	= GTAOParams[3].x;
	params.End		= GTAOParams[3].y;
	params.EndSq	= params.End * params.End;
	params.Scale	= GTAOParams[3].z;
	params.Bias  	= GTAOParams[3].w;
	params.MaxTaps  = 8; //TODO

	return params;
}	


#define PI_HALF (PI*0.5)

#if COMPUTE_SHADER
RWTexture2D<float2> HorizonOutTexture;
RWTexture2D<float>	DepthOutTexture;
RWTexture2D<float2> VelocityOutTexture;
RWTexture2D<float> DepthsTexture;
#endif

Texture2D		HistoryTexture;
SamplerState	HistoryTextureSampler;

Texture2D		ZReadTexture;
SamplerState	ZReadTextureSampler;

Texture2D		ZCurrTexture;
SamplerState	ZCurrTextureSampler;

Texture2D		ZPrevTexture;
SamplerState	ZPrevTextureSampler;

Texture2D		VelocityPrevTexture;
SamplerState	VelocityPrevTextureSampler;

float4 PrevScreenPositionScaleBias;
float4 FilterParams;

float ClampScale(float Scale)
{ 
	return clamp(Scale, 2.0, 8.0);
}

float FalloffFn(FalloffParams FalloffParam, float distSq)
{
	return  2.0 * saturate(distSq * FalloffParam.Scale + FalloffParam.Bias);
}

float3 GetViewSpacePosFromHZB(float2 UV, float MipLevel)
{
	float SceneDepth = GetDepthFromAOInput(UV);

	float2 HZBUV;
	HZBUV.x = UV.x * HZBRemapping.x + HZBRemapping.z;
	HZBUV.y = UV.y * HZBRemapping.y + HZBRemapping.w;
	SceneDepth = Texture2DSampleLevel( PostprocessInput1, PostprocessInput1Sampler, HZBUV, MipLevel).r;
	SceneDepth = ConvertFromDeviceZ(SceneDepth);

	return ScreenToViewPos(UV, SceneDepth);
}


float3 GetNormal(float2 UV, float3 ViewSpacePosMid)
{
	float3 ViewSpaceNormal;

#if USE_NORMALBUFFER

	// Get the normal from the normal buffer
	float3 WorldNormal		= GetGBufferData(UV, false).WorldNormal;
	ViewSpaceNormal	= normalize(mul(WorldNormal, (float3x3)View.TranslatedWorldToView));

#else
	// Get the normal derived from the depth buffer
	float2 DeltaUV = View.BufferSizeAndInvSize.zw;
	
	float DeviceZ		= Texture2DSampleLevel(SceneTexturesStruct.SceneDepthTexture, SceneTexturesStruct.SceneDepthTextureSampler, UV,0).r;									
	float DeviceZLeft	= Texture2DSampleLevel(SceneTexturesStruct.SceneDepthTexture, SceneTexturesStruct.SceneDepthTextureSampler, UV + float2(-DeltaUV.x,  0.0f),0).r;		
	float DeviceZTop	= Texture2DSampleLevel(SceneTexturesStruct.SceneDepthTexture, SceneTexturesStruct.SceneDepthTextureSampler, UV + float2( 0.0f     , -DeltaUV.y),0).r;	
	float DeviceZRight	= Texture2DSampleLevel(SceneTexturesStruct.SceneDepthTexture, SceneTexturesStruct.SceneDepthTextureSampler, UV + float2( DeltaUV.x,  0.0f),0).r;		
	float DeviceZBottom = Texture2DSampleLevel(SceneTexturesStruct.SceneDepthTexture, SceneTexturesStruct.SceneDepthTextureSampler, UV + float2( 0.0f     ,  DeltaUV.y),0).r;	

	float DeviceZDdx	= TakeSmallerAbsDelta(DeviceZLeft, DeviceZ, DeviceZRight);
	float DeviceZDdy	= TakeSmallerAbsDelta(DeviceZTop, DeviceZ, DeviceZBottom);

	float ZRight		= ConvertFromDeviceZ(DeviceZ + DeviceZDdx);
	float ZDown			= ConvertFromDeviceZ(DeviceZ + DeviceZDdy);

	float3 Right		= ScreenToViewPos(UV+ float2( DeltaUV.x,      0.0f) , ZRight)-ViewSpacePosMid;
	float3 Down			= ScreenToViewPos(UV+ float2(      0.0f, DeltaUV.y) , ZDown) -ViewSpacePosMid;
		
	ViewSpaceNormal = normalize(cross(Right, Down));
#endif

	return ViewSpaceNormal;
}


float GetLinearDepthProj(float2 ScreenUV)
{
	float DeviceZ = Texture2DSampleLevel(SceneTexturesStruct.SceneDepthTexture, SceneTexturesStruct.SceneDepthTextureSampler, ScreenUV, 0).r;
	return  1.0f / (DeviceZ * View.InvDeviceZToWorldZTransform[2] - View.InvDeviceZToWorldZTransform[3]);
}

float UpdateMaxAngle(float2 UV, float CurrentBiggest, float CurrAng, float PrevAng)
{
#ifdef GTAO_THICKNESS_HEURISTIC
	if(CurrAng >= PrevAng)
	{
		return max(CurrentBiggest, CurrAng);
	}
	else
	{
		float   ThicknessBlend = GTAOParams[1].y;
		return 	lerp(CurrentBiggest, PrevAng ,ThicknessBlend);
	}
#else
	return max(CurrentBiggest, CurrAng);
#endif
}

float SearchForLargestAngleRef(float2 inUV, float2 deltaUV, float3 ViewSpacePosition, float3 ViewDir, FalloffParams FalloffParam )
{
	float BiggestAngle = -1.0f;
	float PrevAngle    = -1.0f;

	float2 UV	   = inUV ;

	// Do first sample so we have a previous to work with 
	for(int i=1; i<=GTAO_NUMTAPS; i++)
	{
		UV					+= deltaUV;
	
		float SceneDepth	= GetDepthFromAOInput(UV);
		float3 SampVS		= ScreenToViewPos(UV, SceneDepth);
	
		float3 DiffV		= (SampVS - ViewSpacePosition) ;
		float distSQ		= dot(DiffV, DiffV);
	
		BRANCH
		if(distSQ < FalloffParam.EndSq)
		{
			float ooDist    = rsqrt(distSQ);
			float cosh		= ooDist * dot(DiffV, ViewDir );
	
			float falloff	= FalloffFn(FalloffParam, distSQ);

			cosh			= cosh - falloff;
			BiggestAngle	= UpdateMaxAngle(inUV, BiggestAngle, cosh, PrevAngle);
			PrevAngle		= cosh;
		}
	}	


	return BiggestAngle;
}



float SearchForLargestAngle(float2 inUV, float2 deltaUV, float3 ViewSpacePosition, float3 ViewDir, FalloffParams FalloffParam)
{
#if GTAO_REF
	return SearchForLargestAngleRef(inUV,  deltaUV,  ViewSpacePosition,  ViewDir, FalloffParam);
#endif

	float BiggestAngle = -1.0f;
	float PrevAngle	   = -1.0f;

	float2 UV	= inUV;

	float MipLevel = 0;
	for(int i=1; i<=GTAO_NUMTAPS; i++)
	{
		if(i==3)
		{
			deltaUV *=2;
			MipLevel++;
		}
		
		if(i==GTAO_NUMTAPS/2)
		{
			deltaUV *=2;
			MipLevel++;
		}

		UV				+= deltaUV;
		
		// Quantize UV to pixel centre
		float2 UV2 = floor( (View.BufferSizeAndInvSize.xy * UV) + float2(0.25,0.25) ) * View.BufferSizeAndInvSize.zw;
		UV2 += View.BufferSizeAndInvSize.zw*0.5;
		
		//	UV = saturate(UV2);

		float3 SampVS	= GetViewSpacePosFromHZB(UV,MipLevel);
		float3 DiffV	= (SampVS - ViewSpacePosition) ;
		float distSQ	= dot(DiffV, DiffV);

		BRANCH
		if(distSQ < FalloffParam.EndSq)
		{
			float ooDist    = rsqrt(distSQ);
			float cosh		= ooDist * dot(DiffV, ViewDir );
	
			float falloff	= FalloffFn(FalloffParam, distSQ);

			cosh			= cosh - falloff;
			BiggestAngle	= UpdateMaxAngle(inUV, BiggestAngle, cosh, PrevAngle);
			PrevAngle		= cosh;
		}

	}


	return BiggestAngle;
}


// Given a screen space Axis this will search for the min and max angles
float2 SearchAxisForAngles(float2 UV, float3 ScreenDir, float3 ViewDir, float3 ViewSpacePos, float Scale, float Offset, FalloffParams FalloffParam)
{
	float2 DeltaUV	= Scale * float2(GTAOParams[2].z * ScreenDir.x, GTAOParams[2].w * ScreenDir.y);
	DeltaUV.y	  *=-1;

	float Ang1 = SearchForLargestAngle( UV + (DeltaUV*Offset),   DeltaUV, ViewSpacePos, ViewDir, FalloffParam);
	float Ang2 = SearchForLargestAngle( UV - (DeltaUV*Offset),  -DeltaUV, ViewSpacePos, ViewDir, FalloffParam);
	return float2(Ang1, Ang2);
}

float ComputeInnerIntegral(float2 Angles, float3 ScreenDir, float3 ViewDir, float3 ViewSpaceNormal, float SceneDepth)
{
	// Given the angles found in the search plane we need to project the View Space Normal onto the plane defined by the search axis and the View Direction and perform the inner integrate
	float3 PlaneNormal		= normalize(cross(ScreenDir,ViewDir));
	float3 Perp				= cross(ViewDir, PlaneNormal);
	float3 ProjNormal		= ViewSpaceNormal - PlaneNormal * dot(ViewSpaceNormal, PlaneNormal);

	float LenProjNormal		= length(ProjNormal);
	float RecipMag			= 1.0f / (LenProjNormal+1e-6);
	float CosAng			= dot(ProjNormal, Perp) * RecipMag;	
	float Gamma				= acosFast(CosAng) - PI_HALF;				
	float CosGamma			= dot(ProjNormal, ViewDir) * RecipMag;
	float SinGamma  		= CosAng * -2.0f;					

	// clamp to normal hemisphere 
	Angles.x = Gamma + max(-Angles.x - Gamma, -(PI_HALF) );
	Angles.y = Gamma + min( Angles.y - Gamma,  (PI_HALF) );

#if GTAO_PROJECTED_NORMAL_WEIGHTING==0
	LenProjNormal = 1;
#endif


#if GTAO_COSINE_WEIGHTED_INTEGRAL
	float AO = ( LenProjNormal *  0.25 * 
					    ( (Angles.x * SinGamma + CosGamma - cos((2.0 * Angles.x) - Gamma)) +
				  	      (Angles.y * SinGamma + CosGamma - cos((2.0 * Angles.y) - Gamma)) ));
	AO = saturate(AO / PI_HALF);
#else
	// Uniform weighted AO
	float AO =  2 - (cos(Angles.x) + cos(Angles.y));
	AO = saturate(AO / 2.0 * PI_HALF);
#endif


	// Fade out based on user defined distance
	float Mul = ScreenSpaceAOParams[4].x;
	float Add = ScreenSpaceAOParams[4].y;
	AO = lerp(AO, 1, saturate(SceneDepth * Mul + Add));

	return AO;
}




float3 GetRandomVector(float2 UV )
{
	float2 ViewportUVToRandomUV = ScreenSpaceAOParams[1].xy;
	float3 RandomTexVec = Texture2DSample(RandomNormalTexture, RandomNormalTextureSampler, UV * ViewportUVToRandomUV).rgb;
	RandomTexVec.xy = RandomTexVec.xy * 2 -1;

	float TemporalCos = GTAOParams[0].x;
	float TemporalSin = GTAOParams[0].y;
	float3 RandomVec;

	// Rotate the random Vec
	RandomVec.x = dot(RandomTexVec.xy, float2(TemporalCos, -TemporalSin ));
    RandomVec.y = dot(RandomTexVec.xy, float2(TemporalSin, TemporalCos ));
	RandomVec.z = RandomTexVec.z;

	return RandomVec;
}



/*
*
* HORIZON SEARCH AND INNER INTEGRATE COMBINED
*
*/
void GTAOCombinedPSandCS(in float2 UV, out float4 OutColor, inout float OutDepth)
{
	OutColor = 0;

	// Offset by a fraction of a pixel to unsure we don't hit between pixels when running at half res
	UV +=  PostprocessInput0Size.zw*0.125;

	float DeviceZ		 = LookupDeviceZ(UV);
	float SceneDepth	 = ConvertFromDeviceZ(DeviceZ);

	if(SceneDepth > ScreenSpaceAOParams[4].w)	
	{		
		OutColor = 1;
		return;
	}
	
	float3 RandomAndOffset	= GetRandomVector(UV);
	float2 RandomVec		= RandomAndOffset.xy;
	float  Offset			= RandomAndOffset.z;
	Offset += GTAOParams[0].z;

	float3 ViewSpacePos		= ScreenToViewPos(UV,SceneDepth);

	// Get Normal and transform into viewspace
	float3 ViewSpaceNormal	= GetNormal(UV, ViewSpacePos);

#if GTAO_OPT
	float3 ViewDir			= float3(0,0,-1);
#else
	float3 ViewDir			= -normalize(ViewSpacePos.xyz);
#endif

	float Sum=0.0;

	// Given the depth determine how many pixels away we are guranteed to be outside of the falloff distance.
	float InvTanHalfFov			= ScreenSpaceAOParams[3].w;
	float ScreenPixelsToCutoff  = (GTAOParams[2].x * InvTanHalfFov * 9)  / ViewSpacePos.z ; 
	float Scale = ScreenPixelsToCutoff /  GTAO_NUMTAPS;

	// Clamp the scale. Too small and it won't be jumping by more than 1 pixel. Too much and it'll thrash the cache
	Scale = ClampScale(Scale);

	FalloffParams FalloffParam = ComputeFalloffParams(ViewSpacePos.z);

#if GTAO_REF
	for(int i=0; i<GTAO_NUMROTS; i++)
	{
		float phi			= ((float)i) *  float(PI / GTAO_NUMROTS);
		float3 ScreenDir	= float3(cos(phi), sin(phi), 0.0);
#else
		float3 ScreenDir	= float3(RandomVec.x, RandomVec.y, 0.0);
#endif
		float2 Angles = SearchAxisForAngles( UV ,  ScreenDir,  ViewDir,  ViewSpacePos, Scale, Offset, FalloffParam);

		Angles.x = acosFast(Angles.x);
		Angles.y = acosFast(Angles.y);

		Sum += ComputeInnerIntegral(Angles, ScreenDir, ViewDir, ViewSpaceNormal, SceneDepth);
#if GTAO_REF
	}
#endif

	// user adjust AO
	Sum = Sum   / (float)GTAO_NUMROTS;

	OutColor.r	= Sum ;
	OutDepth	= DeviceZ;

	return;
}


void GTAOCombinedPS(in float4 UVAndScreenPos : TEXCOORD0, out float4 OutColor : SV_Target0)
{
	float Depth =0;
	GTAOCombinedPSandCS(UVAndScreenPos.xy, OutColor, Depth);	
}


#if COMPUTE_SHADER
[numthreads(THREADGROUP_SIZEX, THREADGROUP_SIZEY, 1)]
void GTAOCombinedCS(
	uint2 GroupId : SV_GroupID,
	uint2 DispatchThreadId : SV_DispatchThreadID,
	uint2 GroupThreadId : SV_GroupThreadID) 
{
	float4 OutColor		= 0;
	float OutDepth 		= 10e7;

	int2   PixelPos		= DispatchThreadId + ScreenSpaceAOParams[5].zw; 
	float2 PixelCenter	= (float2)PixelPos + float2(0.5, 0.5);
	float2 BufferUV		= PixelCenter.xy * GTAOParams[2].zw;

	GTAOCombinedPSandCS(BufferUV , OutColor, OutDepth);

	OutTexture[PixelPos]		= OutColor.r;
	DepthOutTexture[PixelPos]   = OutDepth;
}
#endif




/*
*
*	INNER INTEGRATE
*
*/

Texture2D		HorizonsTexture;
SamplerState	HorizonsTextureSampler;
float4			InnerIntegrateParams;


float GTAOInnerIntegratePSandCS(in float2 UV)
{
	// Read the angles buffer
	float SceneDepth	 = GetDepthFromAOInput(UV);		
	if(SceneDepth > ScreenSpaceAOParams[4].w)	
	{		
		return 1;
	}

	float2 Angles			= Texture2DSample(HorizonsTexture, HorizonsTextureSampler, UV).xy;	// Angles computed from previous pass
	Angles				    = Angles *2-1;

	// Get Angle
	float2 RandomVec		= GetRandomVector(UV).xy;
	float3 ScreenDir		= float3(RandomVec.x, RandomVec.y, 0.0);

	// ViewspacePos and Normal
	float3 ViewSpacePos		= ScreenToViewPos(UV, SceneDepth);
	float3 WorldNormal		= GetGBufferData(UV, false).WorldNormal;
	float3 ViewSpaceNormal	= normalize(mul(WorldNormal, (float3x3)View.TranslatedWorldToView));
	float3 ViewDir			= -normalize(ViewSpacePos.xyz);	// TODO - This is a function of UV only.

	Angles.x = acosFast(Angles.x);
	Angles.y = acosFast(Angles.y);

	float AO = ComputeInnerIntegral(Angles, ScreenDir, ViewDir, ViewSpaceNormal, SceneDepth);


	return AO ;
}



void GTAOInnerIntegratePS(in noperspective float4 UVAndScreenPos : TEXCOORD0, out float4 OutColor : SV_Target0)
{
	float AO = 	GTAOInnerIntegratePSandCS(UVAndScreenPos.xy);	
	OutColor = AO;
}


#if COMPUTE_SHADER
[numthreads(THREADGROUP_SIZEX, THREADGROUP_SIZEY, 1)]
void GTAOInnerIntegrateCS(
	uint2 GroupId : SV_GroupID,
	uint2 DispatchThreadId : SV_DispatchThreadID,
	uint2 GroupThreadId : SV_GroupThreadID) 
{

	float DownSampleFactor = InnerIntegrateParams.x;
	float  OutColor		= 0;
	int2   PixelPos		= DispatchThreadId + ScreenSpaceAOParams[5].zw; 
	float2 PixelCenter	= (float2)PixelPos + float2(0.5, 0.5);
	float2 BufferUV		= PixelCenter.xy * GTAOParams[2].zw;

	float AO = GTAOInnerIntegratePSandCS(BufferUV);
	
	OutTexture[PixelPos] = AO;
}
#endif






/*
*
* HORIZON SEARCH ONLY
*
*/

float4 HorizonSearchParams;

float2 HorizonSearchPSandCS(in float2 UV, inout float OutDepth)
{
	float2 OutHorizons = 0;

	float DeviceZ		 = LookupDeviceZ(UV);
	float SceneDepth	 = ConvertFromDeviceZ(DeviceZ);
	OutDepth = DeviceZ;

	if(SceneDepth > ScreenSpaceAOParams[4].w)	
	{		
		OutHorizons = 0;
		return OutHorizons;
	}

	float3 RandomAndOffset		= GetRandomVector(UV);
	float2 RandomVec			= RandomAndOffset.xy;
	float  Offset				= RandomAndOffset.z;
	float3 ScreenDir			= float3(RandomVec.x, RandomVec.y, 0.0);
	
	float3 ViewSpacePos			= ScreenToViewPos(UV, SceneDepth);
	float3 ViewDir				= -normalize(ViewSpacePos.xyz);

	// Given the depth determine how many pixels away we are guranteed to be outside of the falloff distance.
	float InvTanHalfFov			= ScreenSpaceAOParams[3].w;
	float ScreenPixelsToCutoff  = (GTAOParams[2].x * InvTanHalfFov * 13)  / ViewSpacePos.z ; 
	float Scale = ScreenPixelsToCutoff /  GTAO_NUMTAPS;

	// Clamp the scale. Too small and it won't be jumping by more than 1 pixel. Too much and it'll thrash the cache
	Scale = ClampScale(Scale);

	FalloffParams FalloffParam = ComputeFalloffParams(ViewSpacePos.z);


	float2 Angles = SearchAxisForAngles( UV,  ScreenDir,  ViewDir,  ViewSpacePos, Scale, Offset, FalloffParam);
	OutHorizons.rg = Angles*0.5+0.5;

	return OutHorizons;
}


void HorizonSearchPS(in noperspective float4 UVAndScreenPos : TEXCOORD0, float4 SvPosition : SV_POSITION, out float4 OutColor : SV_Target0)
{
	float Depth;

	float2 Horizons = HorizonSearchPSandCS(UVAndScreenPos.xy, Depth);	
	OutColor = float4(Horizons.xy,0,0);
}


#if COMPUTE_SHADER
[numthreads(THREADGROUP_SIZEX, THREADGROUP_SIZEY, 1)]
void HorizonSearchCS(
	uint2 GroupId : SV_GroupID,
	uint2 DispatchThreadId : SV_DispatchThreadID,
	uint2 GroupThreadId : SV_GroupThreadID) 
{
	float DownSampleFactor = HorizonSearchParams.x;

	float2 OutColor		= 0;
	int2   PixelPos		= DispatchThreadId + ScreenSpaceAOParams[5].zw; 
	float2 PixelCenter	= (float2)PixelPos + float2(0.5, 0.5);
	float2 BufferUV		= PixelCenter.xy * GTAOParams[2].zw;

	float OutDepth;
	float2 Horizons = HorizonSearchPSandCS(BufferUV,OutDepth);
	
	HorizonOutTexture[PixelPos] = Horizons;
	DepthOutTexture[PixelPos]   = OutDepth;
}
#endif


Texture2D SceneVelocityTexture;
SamplerState SceneVelocityTextureSampler;
float4 BlendParams;
float3 ReprojectPos(float2 UV, float Depth)
{
	// Given a UV reproject where this was in the previous frame
	// Camera motion for pixel (in ScreenPos space).
	float2 ThisScreen = (UV.xy - View.ScreenPositionScaleBias.wz) / View.ScreenPositionScaleBias.xy;

	float4 ThisClip = float4( ThisScreen, Depth, 1 );
	float4 PrevClip = mul( ThisClip, View.ClipToPrevClip );
	float2 PrevScreen = PrevClip.xy / PrevClip.w;

	float2 Velocity	=  Texture2DSampleLevel(SceneVelocityTexture, SceneVelocityTextureSampler, UV,0).rg;
	if( Velocity.x > 0.0 )
	{
		PrevScreen = ThisClip.xy - DecodeVelocityFromTexture( Velocity );
	}
	
	float2 PrevUV = PrevScreen.xy * PrevScreenPositionScaleBias.xy + PrevScreenPositionScaleBias.zw;
	return float3(PrevUV, PrevClip.z/ PrevClip.w);
}


float ReadHistory(float2 UV, float CurrDepth, float CurrAO, inout float WeightSum)
{
	float	BilinearWeights[4];
	float4 SizeInvSize = PostprocessInput0Size.xyzw;

	float2 PixUV   = (UV * SizeInvSize.xy)-0.5;
	float2 FloorUV = floor(PixUV);
	float2 FracUV  = (PixUV - FloorUV); 
	UV			   = (FloorUV * SizeInvSize.zw) + (SizeInvSize.zw*0.5);

	BilinearWeights[0] = (1.0 -	FracUV.x) * ( 1.0 -	FracUV.y);
	BilinearWeights[1] = (		FracUV.x) * ( 1.0 -	FracUV.y);
	BilinearWeights[2] = (1.0 -	FracUV.x) * (       FracUV.y);
	BilinearWeights[3] = (		FracUV.x) * (       FracUV.y);

	// Read the 4 previous depths and History
	float PrevDepth[4];
	float HistoryAO[4];

	float2 dUV = SizeInvSize.zw;
	
	// TODO - Use GatherR when available
	HistoryAO[0] = Texture2DSample(HistoryTexture, HistoryTextureSampler, UV + float2(	  0,     0)).r;
	HistoryAO[1] = Texture2DSample(HistoryTexture, HistoryTextureSampler, UV + float2(dUV.x,     0)).r;
	HistoryAO[2] = Texture2DSample(HistoryTexture, HistoryTextureSampler, UV + float2(    0, dUV.y)).r;
	HistoryAO[3] = Texture2DSample(HistoryTexture, HistoryTextureSampler, UV + float2(dUV.x, dUV.y)).r;

	PrevDepth[0] = Texture2DSample(ZPrevTexture, ZPrevTextureSampler, UV + float2(    0,     0)).r;
	PrevDepth[1] = Texture2DSample(ZPrevTexture, ZPrevTextureSampler, UV + float2(dUV.x,     0)).r;
	PrevDepth[2] = Texture2DSample(ZPrevTexture, ZPrevTextureSampler, UV + float2(    0, dUV.y)).r;
	PrevDepth[3] = Texture2DSample(ZPrevTexture, ZPrevTextureSampler, UV + float2(dUV.x, dUV.y)).r;

	const float DepthScale = 0.01;
	float VisHistory = 0;
	for(int i=0; i<4; i++)
	{
		float DepthWeight = saturate( 1- (DepthScale * abs(CurrDepth - PrevDepth[i])) );
		WeightSum  += DepthWeight * BilinearWeights[i];
		VisHistory += BilinearWeights[i] * lerp( CurrAO, HistoryAO[i], DepthWeight);
	}


	return VisHistory;
}

float ReadHistoryClamp(float2 UV, float MinAO, float MaxAO)
{
	float	BilinearWeights[4];
	float4 SizeInvSize = PostprocessInput0Size.xyzw;

	float2 PixUV   = (UV * SizeInvSize.xy)-0.5;
	float2 FloorUV = floor(PixUV);
	float2 FracUV  = (PixUV - FloorUV); 
	UV			   = (FloorUV * SizeInvSize.zw) + (SizeInvSize.zw*0.5);

	BilinearWeights[0] = (1.0 -	FracUV.x) * ( 1.0 -	FracUV.y);
	BilinearWeights[1] = (		FracUV.x) * ( 1.0 -	FracUV.y);
	BilinearWeights[2] = (1.0 -	FracUV.x) * (       FracUV.y);
	BilinearWeights[3] = (		FracUV.x) * (       FracUV.y);

	// Read the 4 previous depths and History
	float HistoryAO[4];

	float2 dUV = SizeInvSize.zw;

	// TODO - Use GatherR when available
	HistoryAO[0] = Texture2DSample(HistoryTexture, HistoryTextureSampler, UV + float2(	  0,     0)).r;
	HistoryAO[1] = Texture2DSample(HistoryTexture, HistoryTextureSampler, UV + float2(dUV.x,     0)).r;
	HistoryAO[2] = Texture2DSample(HistoryTexture, HistoryTextureSampler, UV + float2(    0, dUV.y)).r;
	HistoryAO[3] = Texture2DSample(HistoryTexture, HistoryTextureSampler, UV + float2(dUV.x, dUV.y)).r;

	float VisHistory = 0;
	for(int i=0; i<4; i++)
	{
		HistoryAO[i] = clamp(HistoryAO[i], MinAO, MaxAO);
		VisHistory += BilinearWeights[i] * HistoryAO[i];
	}


	return VisHistory;
}

void NeighbourhoodClamp(float2 UV, float BaseAO, inout float MinAO, inout float MaxAO)
{
	float2 dUV = PostprocessInput0Size.zw*1.5;
	float AONeighbour1 = Texture2DSample(PostprocessInput0, PostprocessInput0Sampler, UV + float2(-dUV.x,-dUV.y) ).r;
	float AONeighbour2 = Texture2DSample(PostprocessInput0, PostprocessInput0Sampler, UV + float2(-dUV.x, dUV.y) ).r;
	float AONeighbour3 = Texture2DSample(PostprocessInput0, PostprocessInput0Sampler, UV + float2( dUV.x,-dUV.y) ).r;
	float AONeighbour4 = Texture2DSample(PostprocessInput0, PostprocessInput0Sampler, UV + float2( dUV.x, dUV.y) ).r;

	MinAO = min(BaseAO, min(min(AONeighbour1, AONeighbour2), min(AONeighbour3, AONeighbour4)));
	MaxAO = max(BaseAO, max(max(AONeighbour1, AONeighbour2), max(AONeighbour3, AONeighbour4)));
}


float CompareVeloc(float2 V1, float2 V2)
{
	float2 V12 = V1-V2;
	return 1-saturate( abs(V12.x + V12.y) * 100);

}

void GTAOTemporalFilterPSAndCS(float2 UV, inout float OutAO, inout float OutDepth, inout float2 OutVelocity)
{
	float NewAO					= Texture2DSample(PostprocessInput0, PostprocessInput0Sampler, UV).r;

	// Current depth of the rendered Scene
	float CurrDepthDeviceZ		= Texture2DSample(ZCurrTexture, ZCurrTextureSampler, UV).r;
	float CurrDepth				= ConvertFromDeviceZ( CurrDepthDeviceZ);

	// Previous UV value
	float3 PrevUVDepth			= ReprojectPos( UV,  CurrDepthDeviceZ);
	float  CurrDepthReproject	= ConvertFromDeviceZ(PrevUVDepth.z);
	float2 PrevUV				= PrevUVDepth.xy;

	float2 PixVelocity			= UV - PrevUV;
	float  VelocityMag			= saturate(length(PixVelocity)*100);
	
	// Compare velocities 
	float2 DestVeloc=0;
	{
		float DestDeviceZ		= Texture2DSample(ZCurrTexture, ZCurrTextureSampler, PrevUVDepth.xy).r;
		float3 Reproj			= ReprojectPos( PrevUVDepth.xy,  DestDeviceZ); 
		DestVeloc				= PrevUVDepth - Reproj.xy;
	}

	float VelocCompare			= CompareVeloc(PixVelocity, DestVeloc);

	// Get an acceptable range of values we care about from the current AO
	float RangeVal	   = lerp(0.1, 0.00, VelocityMag);
	float MinAO = saturate(NewAO - RangeVal);
	float MaxAO = saturate(NewAO + RangeVal);

	// Simple history value
	float HistoryPrevUV				= ReadHistoryClamp(PrevUV, MinAO, MaxAO);
	float HistoryThisUV				= Texture2DSample(HistoryTexture, HistoryTextureSampler, UV ).r;
	HistoryThisUV = clamp(HistoryThisUV, MinAO, MaxAO);

	float History = HistoryPrevUV;

	History = lerp(HistoryThisUV, HistoryPrevUV, VelocCompare);
	OutAO				= lerp(History, NewAO, 0.2);
	OutDepth			= CurrDepth;
	OutVelocity			= UV - PrevUV;
}


void GTAOTemporalFilterPSAndCS2(float2 UV, inout float OutAO, inout float OutDepth, inout float2 OutVelocity)
{
	float NewAO			= Texture2DSample(PostprocessInput0, PostprocessInput0Sampler, UV).r;

	// Current depth of the rendered Scene
	float CurrDepthDeviceZ		= Texture2DSample(ZCurrTexture, ZCurrTextureSampler, UV).r;
	float CurrDepth				= ConvertFromDeviceZ( CurrDepthDeviceZ);
	
	// 
	float3 PrevUVDepth			= ReprojectPos( UV,  CurrDepthDeviceZ);
	float  CurrDepthReproject	= ConvertFromDeviceZ(PrevUVDepth.z);
	float2 PrevUV				= PrevUVDepth.xy;


	float2 ThisVeloc = UV-PrevUVDepth.xy;
	float2 DestVeloc=0;
	{
		float DestDeviceZ		= Texture2DSample(ZCurrTexture, ZCurrTextureSampler, PrevUVDepth.xy).r;
		float3 Blah				= ReprojectPos( PrevUVDepth.xy,  DestDeviceZ); 
		DestVeloc				= PrevUVDepth-Blah.xy;
	}

	// Compare velocities 
	float VelocCompare			= CompareVeloc(ThisVeloc, DestVeloc);

	float WeightSum=0;
	float ReprojectDepth	= ConvertFromDeviceZ( PrevUVDepth.z);
	float HistoryAO			= ReadHistory(PrevUV, CurrDepthReproject, NewAO, WeightSum );

	HistoryAO			= lerp(NewAO, HistoryAO, VelocCompare);

	float PrevDepth		= Texture2DSample(ZPrevTexture, ZPrevTextureSampler, PrevUV).r;
	float Blend			= lerp(1,0.15, WeightSum);

	if((PrevUV.x <= 0.0) || (PrevUV.y <= 0.0) || (PrevUV.x >= 1.0) || (PrevUV.y >= 1.0))
	{
		Blend=1;
	}

	// Neighbourhood clamp 
	float MinAO =0;
	float MaxAO =0;
	NeighbourhoodClamp(UV, NewAO, MinAO,  MaxAO);

	float HalfAO = (MaxAO - MinAO) *0.5;
	float MidAO  = (MinAO + HalfAO);

	// Ensure the HalfAO is at least some minimum ammount. This helps with the history clamp.
	HalfAO = max(HalfAO,0.05*VelocCompare);
	MinAO = saturate(MidAO - HalfAO);
	MaxAO = saturate(MidAO + HalfAO);

	OutAO = (NewAO*Blend) + (HistoryAO* (1-Blend));


	OutAO = clamp(OutAO, MinAO, MaxAO);

	// If a camera cut then Use current data
	if(BlendParams.x > 0.5 )
	{
		OutAO = NewAO;
	}

	OutDepth	= CurrDepthReproject;
	OutVelocity = UV - PrevUV;
}

void GTAOTemporalFilterPS(in noperspective float4 UVAndScreenPos : TEXCOORD0, float4 SvPosition : SV_POSITION, out float4 OutColor : SV_Target0, out float4 OutColor1 : SV_Target1, out float4 OutColor2 : SV_Target2)
{
	float OutAO = 0;
	float OutDepth = 0;
	float2 OutVelocity = 0;
	
	GTAOTemporalFilterPSAndCS(UVAndScreenPos.xy, OutAO, OutDepth, OutVelocity);
	OutColor	= OutAO;
	OutColor1  = OutDepth;
	OutColor2  = float4((OutVelocity*0.5) + 0.5,0,0);
}

#if COMPUTE_SHADER
[numthreads(THREADGROUP_SIZEX, THREADGROUP_SIZEY, 1)]
void GTAOTemporalFilterCS(
	uint2 GroupId : SV_GroupID,
	uint2 DispatchThreadId : SV_DispatchThreadID,
	uint2 GroupThreadId : SV_GroupThreadID) 
{
	float OutColor		= 0;
	float OutDepth		= 0;
	float2 OutVelocity  = 0;

	int2   PixelPos		= DispatchThreadId + ScreenSpaceAOParams[5].zw; 
	float2 PixelCenter	= (float2)PixelPos + float2(0.5, 0.5);
	float2 BufferUV		= PixelCenter.xy * PostprocessInput0Size.zw;

	GTAOTemporalFilterPSAndCS(BufferUV, OutColor, OutDepth, OutVelocity);

	OutTexture[PixelPos]			= OutColor;
	DepthOutTexture[PixelPos]		= OutDepth;
	VelocityOutTexture[PixelPos]	= (OutVelocity*0.5) + 0.5;
}

#endif



#if COMPUTE_SHADER

// This array will store the low res Z samples with a 1 texel border. 
// It is half rez therefore for 8x8 inputs it is 6x6

// Stores the low res samples dilated 1.
// For 8x8 input we only need 36 entries here but we store 64 to simplify access
groupshared float LowResZArray[  THREADGROUP_SIZEX * THREADGROUP_SIZEY]; 
groupshared float LowResAOArray[ THREADGROUP_SIZEX * THREADGROUP_SIZEY]; 

void GatherLowResAODepthSample(int2 pos, out float4 AO, out float4 Depths, out float4 BilinearWeights)
{
	// X and Y here are in full res. Need to gather the 4 closest low res
	int LowResX = (pos.x+1)>>1;
	int LowResY = (pos.y+1)>>1;

	// Get the weights;
	float WeightX = float(pos.x&1)  * 0.5 + 0.25;
	float WeightY = float(pos.y&1)  * 0.5 + 0.25;
	float WeightX1= 1.0f - WeightX;
	float WeightY1= 1.0f - WeightY;

	BilinearWeights = float4(	WeightX  * WeightY, 
								WeightX1 * WeightY, 
								WeightX  * WeightY1, 
								WeightX1 * WeightY1);

	AO		=  float4( 
					LowResAOArray[LowResX + (LowResY*THREADGROUP_SIZEX) + 0],
					LowResAOArray[LowResX + (LowResY*THREADGROUP_SIZEX) + 1],
					LowResAOArray[LowResX + (LowResY*THREADGROUP_SIZEX) + THREADGROUP_SIZEX],
					LowResAOArray[LowResX + (LowResY*THREADGROUP_SIZEX) + THREADGROUP_SIZEX + 1]);

	Depths		= float4(
					LowResZArray[LowResX + (LowResY*THREADGROUP_SIZEX) + 0],
					LowResZArray[LowResX + (LowResY*THREADGROUP_SIZEX) + 1],
					LowResZArray[LowResX + (LowResY*THREADGROUP_SIZEX) + THREADGROUP_SIZEX],
					LowResZArray[LowResX + (LowResY*THREADGROUP_SIZEX) + THREADGROUP_SIZEX + 1]);

}



[numthreads(THREADGROUP_SIZEX, THREADGROUP_SIZEY, 1)]
void GTAOUpsampleCS(
	uint2 GroupId			: SV_GroupID,
	uint2 DispatchThreadId	: SV_DispatchThreadID,
	uint2 GroupThreadId		: SV_GroupThreadID) 
{
	float2 OutColor		= 0;

	// Get Pixel Pos of the group we are processing
	int2   PixelPos				= DispatchThreadId + ScreenSpaceAOParams[5].zw; 

	int2   FullGroupOrigin		= int2(GroupId.x * THREADGROUP_SIZEX, GroupId.y * THREADGROUP_SIZEY) + ScreenSpaceAOParams[5].zw; 
	int2   HalfGroupOrigin		= int2(FullGroupOrigin.x >>1, FullGroupOrigin.y >>1);
	int2   HalfGroupOriginM1	= HalfGroupOrigin.xy - int2(1,1);

	int2   PosInGroup			= GroupThreadId.xy;	// Position with a group

	// Get Full Rez Depth
	float DeviceZ  = PostprocessInput1.Load(int3(PixelPos, 0)).r;
	float FullResZ = ConvertFromDeviceZ(DeviceZ); 
	
	// Get all the low res samples
	float HalfZ   = ZReadTexture.Load(int3(HalfGroupOriginM1 +PosInGroup.xy , 0)).r;
	LowResZArray[PosInGroup.x + (PosInGroup.y * THREADGROUP_SIZEX)] = HalfZ;

	float AO      = saturate(PostprocessInput0.Load(int3(HalfGroupOriginM1 +PosInGroup.xy , 0)).r);
	LowResAOArray[PosInGroup.x + (PosInGroup.y * THREADGROUP_SIZEX)] = AO;

	GroupMemoryBarrierWithGroupSync();

	float4 AO4, Z4, BilinearWeights;
	GatherLowResAODepthSample(PosInGroup, AO4, Z4, BilinearWeights);

	float MinZ = min(min(Z4.x, Z4.y) , min(Z4.z, Z4.w)); 
	float MaxZ = max(max(Z4.x, Z4.y) , max(Z4.z, Z4.w)); 
	float DiffZ = 1.0f / max(MaxZ - MinZ, 0.000000001);

	FullResZ = clamp(FullResZ, MinZ, MaxZ);

	BilinearWeights = 1;

	BilinearWeights.x *= 1.0f - (abs(Z4.x - FullResZ)*DiffZ);
	BilinearWeights.y *= 1.0f - (abs(Z4.y - FullResZ)*DiffZ);
	BilinearWeights.z *= 1.0f - (abs(Z4.z - FullResZ)*DiffZ);
	BilinearWeights.w *= 1.0f - (abs(Z4.w - FullResZ)*DiffZ);

	float Mag = BilinearWeights.x + BilinearWeights.y + BilinearWeights.z + BilinearWeights.w;

	// user adjust AO
	AO = dot(AO4, BilinearWeights) / Mag;

	OutTexture[PixelPos] = AO;
}
#endif



float4 GTAOUpsamplePSAndCS(float2 UV)
{
	float2 Offset = PostprocessInput0Size.zw * 0.25;

	float AO0 = saturate( Texture2DSample(PostprocessInput0, PostprocessInput0Sampler, UV + float2(-Offset.x, -Offset.y)) .r);
	float AO1 = saturate( Texture2DSample(PostprocessInput0, PostprocessInput0Sampler, UV + float2(Offset.x,  -Offset.y)) .r);
	float AO2 = saturate( Texture2DSample(PostprocessInput0, PostprocessInput0Sampler, UV + float2(-Offset.x, Offset.y)) .r);
	float AO3 = saturate( Texture2DSample(PostprocessInput0, PostprocessInput0Sampler, UV + float2(Offset.x, Offset.y)) .r);

	float AO = min(min(AO0, AO1), min(AO2, AO3))  ;
	return float4(AO,0,0,0);
}

void GTAOUpsamplePS(in noperspective float4 UVAndScreenPos : TEXCOORD0,  out float4 OutColor : SV_Target0)
{
	OutColor = GTAOUpsamplePSAndCS(UVAndScreenPos.xy);
}







#if COMPUTE_SHADER

#define ARRAY_SIZE ((THREADGROUP_SIZEX*2) * (THREADGROUP_SIZEY+4) )
groupshared float AOArray[ARRAY_SIZE]; 
groupshared float ZArray[  ARRAY_SIZE];
groupshared float ZDiffArray[  THREADGROUP_SIZEX * THREADGROUP_SIZEY];


void SetAOVal(float AO, int x, int y)
{
	AOArray[ x + (y*THREADGROUP_SIZEX*2)] = AO;
}

void SetZVal(float Z, int x, int y)
{
	ZArray[ x + (y*THREADGROUP_SIZEX*2)] =Z;
}

float GetAOVal(int x, int y)
{
	x+=2;
	y+=2;
	return AOArray[ x + (y*THREADGROUP_SIZEX*2)];
}

float GetZVal(int x, int y)
{
	x+=2;
	y+=2;
	return ZArray[ x + (y*THREADGROUP_SIZEX*2)];
}



[numthreads(THREADGROUP_SIZEX, THREADGROUP_SIZEY, 1)]
void GTAOSpatialFilterCS(
	int   GroupIndex: SV_GroupIndex,
	uint2 GroupId : SV_GroupID,
	uint2 DispatchThreadId : SV_DispatchThreadID,
	uint2 GroupThreadId : SV_GroupThreadID) 
{
	int2 GTId = int2(GroupThreadId);

	// Position on the screen
	int2   PixelPos				= DispatchThreadId + ScreenSpaceAOParams[5].zw; 

	// Origin of the 8x8 block we are filtering
	int2   FullGroupOrigin		= int2(GroupId.x * THREADGROUP_SIZEX, GroupId.y * THREADGROUP_SIZEY) + ScreenSpaceAOParams[5].zw; 
	int2   FullGroupOriginM2	= FullGroupOrigin.xy - int2(2,2);

	// Read 2 depths per thread and place them in the array 
	uint pixIdx = (GroupIndex*2);
	uint XPos = pixIdx%11;
	uint YPos = pixIdx/11;
	SetAOVal(PostprocessInput0.Load(int3(FullGroupOriginM2 + int2(XPos,YPos), 0)).r, XPos, YPos);
	SetZVal( ZReadTexture.Load(     int3(FullGroupOriginM2 + int2(XPos,YPos), 0)).r, XPos, YPos);

	pixIdx = 1+(GroupIndex*2);
	XPos = pixIdx%11;
	YPos = pixIdx/11;
	SetAOVal(PostprocessInput0.Load(int3(FullGroupOriginM2 + int2(XPos,YPos), 0)).r, XPos, YPos);
	SetZVal( ZReadTexture.Load(     int3(FullGroupOriginM2 + int2(XPos,YPos), 0)).r, XPos, YPos);

	GroupMemoryBarrierWithGroupSync();

	// Get the ZDiffs array
	float ThisZ		= GetZVal(GTId.x, GTId.y);

	float XMinusZ	= GetZVal(GTId.x-1, GTId.y);
	float XPlusZ	= GetZVal(GTId.x+1, GTId.y);
	float YMinusZ	= GetZVal(GTId.x, GTId.y-1);
	float YPlusZ	= GetZVal(GTId.x, GTId.y+1);

	float DiffZ_X = min( abs(ThisZ - XMinusZ), abs(ThisZ - XPlusZ) );
	float DiffZ_Y = min( abs(ThisZ - YMinusZ), abs(ThisZ - YPlusZ) );

	BRANCH
	if (any(DispatchThreadId >= (uint2)FilterParams.zw))
	{
		return;
	}

	int x,y;

	float SumAO		= 0;
	float SumWeight = 0;

	for(y=-2; y<2; y++)
	{
		float YDiff = abs(y);

		for(x=-2; x<2; x++)
		{
			// Get value and see how much it compares to the centre with the gradients
			float XDiff = abs(x);

			float Sample_AO = GetAOVal(GTId.x + x, GTId.y + y);
			float SampleZ   = GetZVal( GTId.x + x, GTId.y + y);

			float Weight = 1.0f;
			if((x==0) && (y==0))
			{
				Weight = 1.0f;
			}
			else
			{
				// Compare the Z at this sample with the gradients 
				float SampleZDiff = abs(ThisZ - SampleZ);
				
				SampleZDiff -= XDiff * DiffZ_X;
				SampleZDiff -= YDiff * DiffZ_Y;
			
				const float SpatialFilterWeight = 1000;
				Weight = 1.0f - saturate(SampleZDiff*SpatialFilterWeight );
			}

			SumAO += Sample_AO * Weight;
			SumWeight += Weight;
		}
	}
	SumAO /=SumWeight;

	SumAO = saturate(SumAO * PI_HALF);

	float AmbientOcclusionIntensity = ScreenSpaceAOParams[0].w;
	float AmbientOcclusionPower		= ScreenSpaceAOParams[0].x*0.5;
	// user adjust AO
	SumAO = 1 - (1 - pow(abs(SumAO), AmbientOcclusionPower)) * AmbientOcclusionIntensity;

	OutTexture[PixelPos] = SumAO ;
}
#endif

void GTAOSpatialFilterPS(in noperspective float4 UVAndScreenPos : TEXCOORD0,  out float4 OutColor : SV_Target0)
{
	OutColor = Texture2DSample(PostprocessInput0, PostprocessInput0Sampler, UVAndScreenPos.xy);
}